---
title: KNN 算法
date: 2019-09-03 04:24:16
categories:
  - 数据科学
tags:
  - 机器学习
---

{% asset_img knn.png "knn" %}

K Nearest Neighbor, KNN 算法，应该是最简单的机器学习算法之一。

这里用一个手算的例子说明 KNN 算法的步骤。

<!-- more -->

## 算法步骤

该算法的步骤如下：

1. 决定参数 K，即判断分类时考虑几个“邻居”
2. 计算新的样本与训练数据集里各个观测值的**距离**
3. 将距离由小到大排序，保留前 K 个观测值
4. 获取这 K 个观测值的 category
5. 以这 K 个观测值里占多数的 category 作为新样本的 category

## 手算例子

training data set 如下：

| 自变量1 | 自变量2 | 分类 |
|:-------:|:-------:|:----:|
|    7    |    7    |   1  |
|    7    |    4    |   1  |
|    3    |    4    |   0  |
|    1    |    4    |   0  |

只有2个变量，4个观测值。

假设新的样本是 **(3, 7)**。

### 第1步：选定 K

第1步，要决定一个参数 K。

我们选定参数 k = 3。

### 第2步：计算距离

计算新的样本与训练数据集里各个观测值的**距离**。距离公式采用 euclidean distance。

{% asset_img euc_d.png "euc_d" %}

按照这个公式计算(3, 7)跟各个点的距离：

| 自变量1 | 自变量2 | 距离 |
|:-------:|:-------:|:----:|
|    7    |    7    |  16  |
|    7    |    4    |  25  |
|    3    |    4    |   9  |
|    1    |    4    |  13  |

### 第3步：排序

按照距离，由小到大排序，保留前 k 个：

| 自变量1 | 自变量2 | 距离 |
|:-------:|:-------:|:----:|
|    3    |    4    |   9  |
|    1    |    4    |  13  |
|    7    |    7    |  16  |

### 第4步：获取 category

获取这几个值的 category

| 自变量1 | 自变量2 | 距离 | 分类 |
|:-------:|:-------:|:----:|:----:|
|    3    |    4    |   9  |   0  |
|    1    |    4    |  13  |   0  |
|    7    |    7    |  16  |   1  |

### 第5步：确定 category

以这 K 个观测值里占多数的 category 作为新样本的 category。

占多数的分类是 0，所以 (3,7) 被判断为是 0。

## 小结

KNN 算法的简单之处在于：

- 没有新的概念，懂高中数学的人都能理解这个算法
- 是*无参数*方法，不用考虑统计学公式
- 算法步骤比较简单

这个算法的实现可以当作一个 python 练习来做。