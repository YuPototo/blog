{"meta":{"title":"商业与数据","subtitle":"","description":"","author":"Yu Qin","url":"http://yoursite.com","root":"/blog/"},"pages":[{"title":"about","date":"2020-01-17T10:00:00.000Z","updated":"2020-01-22T19:42:39.787Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"This is test。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });"}],"posts":[{"title":"模拟“中心极限定理” - 比例篇","slug":"simu-clt-2","date":"2020-01-22T19:13:45.000Z","updated":"2020-01-22T19:42:39.787Z","comments":true,"path":"2020/01/22/simu-clt-2/","link":"","permalink":"http://yoursite.com/2020/01/22/simu-clt-2/","excerpt":"上一篇模拟了均值的中心极限定理，这一篇再扩展一下。 中心极限定理不只适用于均值，还可用于对“占比”的描述。什么是占比呢？ 例子： 总统选举中候选人 A 的支持率 \bApp Store 落地页的下载转化率 \b\b认为 Google 股票会上涨的股民比例 … 在互联网行业，这个指标最重要的应用应该是各种转化率。 中心极限定理公诉我们，当样本足够大时，样本的比例符合正态分布。 该分布的均值等于总体的分布： \b 该分布的标准差可以用如下公式计算：\b 接下来我们模拟 proportion 的中心极限定理。 \b","text":"上一篇模拟了均值的中心极限定理，这一篇再扩展一下。 中心极限定理不只适用于均值，还可用于对“占比”的描述。什么是占比呢？ 例子： 总统选举中候选人 A 的支持率 \bApp Store 落地页的下载转化率 \b\b认为 Google 股票会上涨的股民比例 … 在互联网行业，这个指标最重要的应用应该是各种转化率。 中心极限定理公诉我们，当样本足够大时，样本的比例符合正态分布。 该分布的均值等于总体的分布： \b 该分布的标准差可以用如下公式计算：\b 接下来我们模拟 proportion 的中心极限定理。 \b 场景假设某 app 有100万个用户，该 app 想上线一个新功能，但直接全量上线是不太好，风险太大。 为了测试这个新功能是否受欢迎，产品经理决定先让一部分用户试用，然后再对他们做调查，提问他们是否喜欢这个功能。 根据中心极限定理，样本量越大越符合正态分布，且方差越小。我们模拟不同样本量下的估计值的分布。 R 代码代码跟上一篇差不多。 准备1234567library(tidyverse)library(ggpubr)set.seed(123)pop_size &lt;- 1000000pop_player &lt;- c(rep(\"like\", 0.7 * pop_size), rep(\"dislike\", 0.3 * pop_size)) 准备需要的 package，并定好随机数。然后创建100万名用户，其中有70%的人会喜欢新功能，有30%的人会不喜欢。 函数：抽样、模拟、做图这段代码跟上一篇差不多： sample_player 进行一次抽样，可以选择抽样人数 simulate_df 模拟 n 次实验 draw_plot 对 n 次实验的结果做图 simulate_and_draw 封装了上面几个函数 针对这篇的主题，某些地方做了调整。 1234567891011121314151617181920212223242526272829sample_player &lt;- function(size) { sample_vec &lt;- sample(pop_player, size = size) sum(sample_vec == \"like\") / size}simulate_df &lt;- function(size, n) { df &lt;- data.frame(sample_prop = rep(0, n)) for (i in 1:n) { df[i, 1] &lt;- sample_player(size) } df}draw_plot &lt;- function(df, size, bin_width=0.1) { stan_dev &lt;- round(sd(df$sample_prop), 2) ggplot(df, aes(x = sample_prop)) + geom_histogram(binwidth = bin_width) + scale_x_continuous(labels = scales::percent, limits = c(0: 1)) + labs(title = str_c('调查', size, '个玩家'), subtitle = str_c('点估计标准差 = ', stan_dev), x = '表示\"喜欢的\"玩家占比', y = '频数') }simulate_and_draw &lt;- function(size, n = 5000, bin_width = 0.1) { simulate_df(size, n) %&gt;% draw_plot(size, bin_width)} 做图下面计算抽样5人、10人、20人、40人、100人和1000人的情况，为了节约运算时间，模拟5000轮： 123456789p1 &lt;- simulate_and_draw(5, bin_width = 0.1)p2 &lt;- simulate_and_draw(10, bin_width = 0.05)p3 &lt;- simulate_and_draw(20, bin_width = 0.05)p4 &lt;- simulate_and_draw(40, bin_width = 0.025)p5 &lt;- simulate_and_draw(100, bin_width = 0.01)p6 &lt;- simulate_and_draw(1000, bin_width = 0.003)ggarrange(p1, p2, p3, p4, p5, p6, nrow = 3, ncol = 2) 结果做图结果如下： \b 可以看到： 样本数量足够大时，样本内 proportion 的分布接近正态分布 样本数量越大，分布的标准差越小 对于一个100万用户的产品，如果新功能受到70%人喜欢，调查1000个用户就足以知道新功能是否受欢迎了。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"统计理论","slug":"统计理论","permalink":"http://yoursite.com/categories/%E7%BB%9F%E8%AE%A1%E7%90%86%E8%AE%BA/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"模拟“中心极限定理” - 均值篇","slug":"simu-clt-1","date":"2020-01-22T17:39:54.000Z","updated":"2020-01-22T19:42:39.787Z","comments":true,"path":"2020/01/22/simu-clt-1/","link":"","permalink":"http://yoursite.com/2020/01/22/simu-clt-1/","excerpt":"\b\b中心极限定理是统计学里最重要的定理，可能没有之一。 按照中心极限定理，在样本量足够大的时候，任何分布的样本均值，都\b会接近正态分布。 不管原先的分布是二项分布、泊松分布或任何千奇百怪的分布，如果我们对这个分布做抽样，只要样本量够大，作为随机变量的样本均值会呈现正态分布。 下图是个形象的说明： \b 这个定理在数学上有严谨的证明。数学证明太抽象，我们可以用 simulation 更好地展示这个定理。 \b","text":"\b\b中心极限定理是统计学里最重要的定理，可能没有之一。 按照中心极限定理，在样本量足够大的时候，任何分布的样本均值，都\b会接近正态分布。 不管原先的分布是二项分布、泊松分布或任何千奇百怪的分布，如果我们对这个分布做抽样，只要样本量够大，作为随机变量的样本均值会呈现正态分布。 下图是个形象的说明： \b 这个定理在数学上有严谨的证明。数学证明太抽象，我们可以用 simulation 更好地展示这个定理。 \b 样本数量与均值的分布根据中心极限定理，样本均值在样本量足够大时符合正态分布，且该正态分布的均值是： \b 另外，样本均值的正态分布的标准差是： \b 所以，随着样本逐渐增大，我们应该能观察到： \b均值的分布逐渐接近正态分布 该正态分布的标准差越来越小 扔骰子扔骰子是个经典的概率现象。从1到6，概率都是1/6。这个分布的数学期望是3.5（有兴趣的小伙伴可以手动算算）。 如果投1次骰子，相当于抽取一个样本，虽然数学期望仍然是3.5，但我们只会观察到有1/6的概率落在1到6中任意一个数字上。我们重复10000次抽样，并记录每次的均值（其实就是投到的数字，因为只有1次），应该会看到1到6的数字都占1/6。 如果投10次骰子，相当于抽取10个样本，均值会相对集中。我们重复10000次抽样，并记录每次的均值，应该会看到均值相对之前集中。 如果投100次骰子，相当于抽取100个样本，均值会非常接近3.5.我们重复10000次抽样，并记录每次的均值，按照中心极限定理，均值的分布会是个方差很小的正态分布。 在现实生活里，如果模拟10000次抽样，且每次抽样要投100次骰子，我们一共要投个100万次骰子。实在不可能。好在现在有了计算机，我们可以让计算机模拟投掷骰子的过程。 R 代码用 R 语言模拟投掷结果并做图。 \b准备R代码1234library(tidyverse)library(ggpubr)set.seed(123) 使用 tidyverse 包，主要是为了使用 dplyr 和 ggplot2。ggpubr 包是为了合并图片。为了保证分析的可重复性，需要先设定一个随机数种子，这样能保证每次“随机”的结果是一样的。 函数：掷骰子R代码12345simu_dice_mean &lt;- function(size) { dice_vec &lt;- 1:6 sample_mean &lt;- sum(sample(dice_vec, size, replace = T)) / size sample_mean} simu_dice_mean 函数模拟了掷骰子后计算均值的过程，我给了一个参数size，表示掷骰子的次数。这里会返回本次投掷的均值。 函数：重复实验 n 次R代码1234567simulate_df &lt;- function(size, n) { df_mean &lt;- data.frame(sample_mean = rep(0, n)) for (i in 1:n) { df_mean[i, 1] &lt;- simu_dice_mean(size) } df_mean} simulate_df 重复了 n 次 simu_dice_mean，生成一个 data frame，包含 n 个均值。如果需要经常做模拟，这一步代码可以大大优化。不过我只模拟这一次，所以用了最直接的 for loop。 函数：做图R代码12345678910draw_plot &lt;- function(df, size, bin_width) { stan_dev &lt;- round(sd(df$sample_mean), 2) ggplot(df, aes(x = sample_mean)) + geom_histogram(binwidth = bin_width) + scale_x_continuous(limits = c(0.5, 6.5)) + labs(title = str_c('投掷骰子', size, '次'), subtitle = str_c('点估计标准差 = ', stan_dev), x = '均值', y = '频数') } 前一步返回了均值的 data frame，我们可以用其画出直方图，展示分布情况。同时我在这一步计算了这组分布的标准差。 函数：汇总R代码1234simulate_and_draw &lt;- function(size, n = 10000, bin_width) { simulate_df(size, n) %&gt;% draw_plot(size, bin_width)} 把 simulate_df 和 draw_plot 两个函数结合，生成一个新的函数simulate_and_draw。准备工作结束。 调用函数我们依次计算并画出掷骰子1次、5次、10次、20次、50次和100次的模拟结果（模拟10000次实验）： R代码12345678910p1 &lt;- simulate_and_draw(size = 1, bin_width = 0.2)p2 &lt;- simulate_and_draw(size = 5, bin_width = 0.2)p3 &lt;- simulate_and_draw(size = 10, bin_width = 0.2)p4 &lt;- simulate_and_draw(size = 20, bin_width = 0.15)p5 &lt;- simulate_and_draw(size = 50, bin_width = 0.1)p6 &lt;- simulate_and_draw(size = 200, bin_width = 0.03)# 结合6个图片ggarrange(p1, p2, p3, p4, p5, p6, nrow = 3, ncol = 2) 模拟结果如下图： \b 可以清晰地看到： 分布的均值越来越集中在3.5 分布的标准差越来越小 类似的模拟，不只是掷骰子所属的离散均匀分布能做，其他分布也能做。如果我是老师，就会在这里布置一门作业：在总体分布符合泊松分布的情形下模拟中心极限定理。 以上就是中心极限定理的直观展示了。有了中心极限定理，对均值做统计推断才成为可能。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"统计理论","slug":"统计理论","permalink":"http://yoursite.com/categories/%E7%BB%9F%E8%AE%A1%E7%90%86%E8%AE%BA/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"ggplot 系列之：ggTimeSeries","slug":"gg-daily-heatmap","date":"2020-01-21T22:33:41.000Z","updated":"2020-01-22T19:42:39.779Z","comments":true,"path":"2020/01/21/gg-daily-heatmap/","link":"","permalink":"http://yoursite.com/2020/01/21/gg-daily-heatmap/","excerpt":"今天看到一个有趣的 R pakcage：ggTimeSeries 能够对时间序列数据做出有趣的图片。 \b","text":"今天看到一个有趣的 R pakcage：ggTimeSeries 能够对时间序列数据做出有趣的图片。 \b 日期热点图我最喜欢的是下面这个日期热点图，它能够展示连续变量在一年里每天的数据情况，月份在 x 轴，工作日在 y 轴，数据大小用填充色表示。 我随便找了个每日温度数据，做出了最上面那个图，做图代码如下： 1234567891011121314# 基本图p0 &lt;- df %&gt;% ggplot_calendar_heatmap('date','meantemp', dayBorderColour = '#cccccc', monthBorderColour = '#777777')# 加工p0 + scale_fill_continuous(low = 'green', high = 'red') + facet_wrap(~Year, ncol = 1) + labs(x = NULL, y = NULL, fill = NULL, title = '每日平均气温') + theme_minimal() + theme(text=element_text(family=\"Songti TC Regular\")) 这个展示方式很适合用来展示有工作日趋势和季度趋势的时间序列数据，比如每日销售、网站访问量。 寒假和暑假经常是游戏流量的高峰，这个信息就能在这个图片上一目了然。 \b工作日的游戏流量低于周末，也很适合在这个图表上展示。 waterfall 图这个 package 里还有一个我喜欢的图，waterfall 图： Waterfall 图用箭头标注了数据的每日变化，展示每天都有波动的数据很合适，比如股票价格等。 上图的做图代码： 123456789101112131415# 基本图df %&gt;% ggplot_waterfall('date','meantemp')# 加工p0 + labs(x = NULL, y = NULL, color = '变化', title = '每日平均气温') + theme_classic(16) + theme(text=element_text(family=\"Songti TC Regular\"), plot.title = element_text(hjust = 0.5)) theme(text=element_text(family=\"Songti TC Regular\")) 这个 package 里还有其他几个可视化方法，个人觉得不太实用，有兴趣的同学可以去看看。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据可视化","slug":"数据可视化","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"ggplot 系列之：别用漏斗图","slug":"gg-funnel","date":"2020-01-21T22:33:24.000Z","updated":"2020-01-22T19:42:39.779Z","comments":true,"path":"2020/01/21/gg-funnel/","link":"","permalink":"http://yoursite.com/2020/01/21/gg-funnel/","excerpt":"分析用户的转化路径时，经常需要使用漏斗图。但是，漏斗图并不是多好的数据可视化方案。 漏斗图的问题跟饼图有点相似：用面积表示数量多少，而人类视觉对面积的敏感度不够。 下面这张图是我从网上找到的漏斗图，我会用同样的数据做一个柱状图版本。 \b","text":"分析用户的转化路径时，经常需要使用漏斗图。但是，漏斗图并不是多好的数据可视化方案。 漏斗图的问题跟饼图有点相似：用面积表示数量多少，而人类视觉对面积的敏感度不够。 下面这张图是我从网上找到的漏斗图，我会用同样的数据做一个柱状图版本。 \b 准备数据原图展示了销售的四个步骤各自有多少人。 我们先准备一份数据： 1234df &lt;- data.frame( stage = c('Prospects', 'Price Quotes', 'Negotiations', 'Closed Sales'), people = c(12000, 6800, 3000, 850)) 做图漏斗图有个值得借鉴的设计思路：从上到下展示数据的阶段性变化。我们想在柱状图上借用这个设计。 基本版先画一个基本版 123456789ggplot(df, aes(x = stage, y = people)) + geom_bar(stat = 'identity', width = 0.7) + geom_text(aes(label = people), hjust= -0.1) + scale_y_continuous(limits = c(0, 13000)) + labs(title = '销售漏斗图', y = '人数', x= NULL) + coord_flip() + theme_classic(16) 几个要点： 使用 coord_flip 可以把柱状图变成横向 使用geom_text标注人数 使用theme_classic 主题，减少画面中的元素。 结果如图： 加入百分比有的漏斗图会显示每个步骤还剩下多少比例的人数。我也想借用这个思路。 先加工数据： 12df_2 &lt;- df %&gt;% mutate(pct = str_c(round(people / max(people) * 100), '%')) 我新建了一列，计算各个阶段相对于最开始人数的百分比。 然后做图： 12345678910ggplot(df_2, aes(x = stage, y = people)) + geom_bar(stat = 'identity', width = 0.7) + geom_text(aes(label = people), hjust= 1.1, color = 'white') + geom_text(aes(y = max(people) * 1.05, label = pct), hjust= 0) + scale_y_continuous(limits = c(0, 13000)) + labs(title = '销售漏斗图', y = '人数', x= NULL) + coord_flip() + theme_classic(16) 跟之前相比有两个变化： 人数移到柱子内部，调整为白色 新增一个 geom_text，用于展示百分比 结果如下： 视觉调整仔细看漏斗图，我发现漏斗图还有一个好处：图片内的元素很少，让人感觉舒服。 参考漏斗图，我们修改自己的柱状图设计。 代码： 1234567# p1 是上一个图片p1 + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks =element_blank(), axis.line = element_blank(), plot.title = element_text(hjust = 0.3)) + scale_y_continuous(limits = c(0, 14500), expand = c(0,0)) 要点： 隐藏 x 轴和 y 轴的线、刻度 图片的标题相对居中 减少柱子和 y 轴之间的 padding 结果如下： 能够修改的地方还有很多，比如柱子是不是太短太粗，颜色是不是可以优化，百分比的展示是不是可以更明确。这里就不再细究了。 参考 Bad Graphics – Funnel Chart Funnel Charts Suck and You Shouldn’t Use Them document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据可视化","slug":"数据可视化","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"ggplot系列之：theme","slug":"ggplot-theme","date":"2020-01-21T14:21:31.000Z","updated":"2020-01-22T19:42:39.783Z","comments":true,"path":"2020/01/21/ggplot-theme/","link":"","permalink":"http://yoursite.com/2020/01/21/ggplot-theme/","excerpt":"$\\alpha$ 人靠衣装，图靠 theme 装。好看的数据可视化，会一眼抓住人眼球，让你的报告更有说服力。 ggplot 生态提供了丰富的 theme 选择，如果你对已有的 theme 不满意，还可以自己创造 theme。 这篇文章介绍几个不错的 theme。 \b\b","text":"$\\alpha$ 人靠衣装，图靠 theme 装。好看的数据可视化，会一眼抓住人眼球，让你的报告更有说服力。 ggplot 生态提供了丰富的 theme 选择，如果你对已有的 theme 不满意，还可以自己创造 theme。 这篇文章介绍几个不错的 theme。 \b\b 数据和图片先用 Gapminder 数据做一个基础图。 12df &lt;- gapminder %&gt;% filter(year == 2007) Gapminder 里有1950年代到2007年各国的预期寿命、人口、人均 GDP 等数据。 我们只看2007年的样本，前几列数据如下： country continent year lifeExp pop gdpPercap Afghanistan Asia 2007 43.828 31889923 974.5803 Albania Europe 2007 76.423 3600523 5937.0295 Algeria Africa 2007 72.301 33333216 6223.3675 Angola Africa 2007 42.731 12420476 4797.2313 Argentina Americas 2007 75.320 40301927 12779.3796 Australia Oceania 2007 81.235 20434176 34435.3674 我比较感兴趣的是人均 GDP 和预期寿命的相关性。所以，我会画一个人均 GDP 和预期寿命的散点图。除此之外，这里还有人口数据和国家所属的大洲，为了展示更多信息，我们可以用\b点的大小表示人口，用颜色表示所属的大洲。 做图代码如下： 1234567891011121314p0 &lt;- ggplot(data = df, aes(x = gdpPercap, y = lifeExp, size = pop, color = continent)) + geom_point() + scale_x_continuous(trans = 'log', labels = round) + labs(title = '人均gdp vs. 预期寿命', x = 'log(人均 GDP)', y = '预期寿命', color = '大洲', size = '人口', caption = \"数据来源: gapminder\") 我怀疑人均 GDP 用 log 形式更能展示线性关系，所以这里对人均 GDP 数据做 log 处理。 ggplot 的内置 themeggplot 内置了至少8个 theme，我选出了几个自己比较喜欢的。 默认: theme grayggplot 的默认 theme 是 theme_gray： 这个 theme 已经可以应付大部分场合了。 theme dark既然有 gray，当然就有 dark。theme_dark 会把底色变黑，适用于在黑暗的环境做报告。 theme minimaltheme_minimal 是一个贯彻简单原则的 theme。 theme classictheme_classic 是我的最爱，这应该是数据可视化最经典的主题。 package：ggthemesggthemes 是一个包含了十数个主题的 package，这里介绍其中的几个。 theme fewtheme_few 也是个简单原则的主题。 theme economisttheme_economist 是个参考《经济学人》风格设计的主题。 theme gdocstheme_gdocs 是个参考 google docs 风格设计的主题。 theme 538theme_fivethirtyeight 是个参考数据网站 fivethirtyeight 设计的主题。 theme_excelpackage 作者出于搞笑目的做了一个经典 excel 主题。 作者在 ggthemes 的文档里写道： Theme to replicate the ugly monstrosity that was the old gray-background Excel chart. Please neveruse this. 😛 修改主题如果想要微调某个主题，需要用到 ggplot 的 theme 方法。 比如我们想修改默认主题： 标题和副标题剧中 标题改为红色、加粗 副标题改为深绿色p 我们可以这样做： 123# p1 是最开始画的图p1 + theme(plot.title = element_text(color = 'red', hjust = 0.5, size = 20), plot.subtitle = element_text(color = 'darkgreen', hjust = 0.5)) 结果如下： \b这只是个说明性的例子，ggplot 提供了非常丰富的图片修改可能，图片上的任何“元素”都可以使用某个命令修改。 bonus: theme_xkcd最近刷到一个有意思的主题：xkcd。需要安装 package xkcd。这是个卡通风格的主题，需要字体 xkcd，不支持中文。 用 theme_xkcd() 做图如下： 太可爱了 😆 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据可视化","slug":"数据可视化","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"ggplot 系列之：折线图","slug":"ggplot-line","date":"2020-01-21T12:35:36.000Z","updated":"2020-01-22T19:42:39.783Z","comments":true,"path":"2020/01/21/ggplot-line/","link":"","permalink":"http://yoursite.com/2020/01/21/ggplot-line/","excerpt":"折线图，经常用来展示时间序列数据。 \b\b","text":"折线图，经常用来展示时间序列数据。 \b\b \b准备数据这里使用 R 自带的 UKLungDeaths 数据，记录了英国1974到1979年每个月因为肺病死亡的人数。 源数据是 ts 格式，需要现转换成 ggplot 需要的 data.frame 格式，使用 tsbox 包。 12345678# 用于基础做图df &lt;- ts_df(ts_c(ldeaths))# 用于分组做图df_2 &lt;- ts_df(ts_c(fdeaths, mdeaths))names(df_2)[1] &lt;- 'gender'df_2 &lt;- df_2 %&gt;% mutate(gender = ifelse(gender == 'fdeaths', 'female', 'male')) 这里准备了两个 data.frame。第一个 df 是每月因为肺病死亡的总人数，第二个 df 是分性别的死亡人数。 第1组数据的前几行: time value 1974-01-01 3035 1974-02-01 2552 1974-03-01 2704 1974-04-01 2554 1974-05-01 2014 1974-06-01 1655 第2组数据的前几行： time value gender 1974-01-01 901 female 1974-02-01 689 female 1974-03-01 827 female 1974-04-01 677 female 1974-05-01 522 female 1974-06-01 406 female 第2组数据多了一个表示性别的变量gender。 基本折线图先画一个每月总死亡人数的图： 12345678df %&gt;% ggplot(aes(x = time, y = value)) + geom_line() + scale_x_date(date_breaks = '2 years', date_labels = \"%Y-%m\") + labs(title = '1974-1979年英国死于肺病的人数/每月', x = '月份', y = '死亡人数') geom_line 是画折线图的函数。 这里还出现了一个常用的方法scale_x_date，处理时间格式时很方便。我用 date_breaks = '2 years' 表示 x 轴的标签每隔两年显示，然后用date_labels = '%Y-%m'将显示的格式设定为”xxxx年-xx月”。 做图结果如下： 分组折线图有时我们需要对不同的组别画折线： 123456789df_2 %&gt;% ggplot(aes(x = time, y = value, color = gender)) + geom_line() + scale_x_date(date_breaks = '2 years', date_labels = \"%Y-%m\") + labs(title = '1974-1979年英国死于肺病的人数/每月', x = '月份', y = '死亡人数', color = '性别') 这里的关键是第2行的color = gender。 做图结果如下： 折线图 + 点有时我们想要同时展示折线和点： 12345678910df_2 %&gt;% ggplot(aes(x = time, y = value, color = gender)) + geom_line() + geom_point() + scale_x_date(date_breaks = '2 years', date_labels = \"%Y-%m\") + labs(title = '1974-1979年英国死于肺病的人数/每月', x = '月份', y = '死亡人数', color = '性别') 加上 geom_point 即可。 做图结果如下： document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据可视化","slug":"数据可视化","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"ggplot系列之：柱状图","slug":"ggplot-barplot","date":"2020-01-20T12:25:12.000Z","updated":"2020-01-22T19:42:39.779Z","comments":true,"path":"2020/01/20/ggplot-barplot/","link":"","permalink":"http://yoursite.com/2020/01/20/ggplot-barplot/","excerpt":"柱状图，个人认为最实用的可视化图形。这里总结如何在 ggplot2 里使用柱状图。 \b\b","text":"柱状图，个人认为最实用的可视化图形。这里总结如何在 ggplot2 里使用柱状图。 \b\b 默认柱状图先生成一份简单的数据： 1234df &lt;- data.frame( user_num = c(3000, 5000, 7000), version = factor(c('version 1', 'version 2', 'version 3'))) 我们生成了某 app 不同版本下的用户数据，我们需要展示这个信息。 12345ggplot(data=df, aes(x=version, y = user_num)) + geom_bar(stat=\"identity\", width = 0.5) + labs(title = '各个版本的用户数量', x = '版本', y = '用户数') 最重要的代码是第7行的geom_bar，其中stat=\"identity\"指直接用 data.frame 里的数字作为 y 轴的值。width 是柱子的宽度。 结果如下： 进阶版：分组app 的用户数据可以按照各个维度做拆分，最常用的一个维度是性别。我们把用户数拆分为不同性别。 12345df_2 &lt;- data.frame( user_num = c(1600, 1400, 3000, 2000, 4000, 3000), version = factor(c('version 1', 'version 1', 'version 2', 'version 2', 'version 3', 'version 3')), gender = factor(c('male', 'female', 'male', 'female', 'male', 'female'))) 然后我们展示分组柱状图。 1234567ggplot(data=df_2, aes(x=version, y = user_num, fill = gender)) + geom_bar(stat=\"identity\", width = 0.5, position = 'dodge') + scale_fill_brewer(palette=\"Set2\") + labs(title = '各个版本的用户数量', x = '版本', y = '用户数', fill = '性别') 我在第一行用了fill = gender，实现了对不同组填色。然后在第二行用了position = 'dodge'，实现了对把不同组的柱子并排展示。如果不使用这个参数，柱子会叠加在一起展示。为了替换默认颜色，我在第三行用了scale_fill_brewer(palette=\"Set2\")，这里的 Set2是调色板名称。 结果如下： 在柱子上显示数量有时为了更清晰地展示信息，我们需要在柱子上展示数字。 这时需要用到 geom_text(): 12345678ggplot(data=df_2, aes(x=version, y = user_num, fill = gender)) + geom_bar(stat=\"identity\", width = 0.8, position = 'dodge') + geom_text(aes(label = user_num), position = position_dodge(0.8), vjust = -0.2) + scale_fill_brewer(palette=\"Set2\") + labs(title = '各个版本的用户数量', x = '版本', y = '用户数', fill = '性别') 第3行就是 geom_text() 命令，我们令文字内容等于user_num。 结果如下： 更多柱状图控制，可以参考 ggplot2 的文档。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据可视化","slug":"数据可视化","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"ggplot 系列之：饼图","slug":"ggplot-pie-chart","date":"2020-01-20T05:20:15.000Z","updated":"2020-01-22T19:42:39.783Z","comments":true,"path":"2020/01/20/ggplot-pie-chart/","link":"","permalink":"http://yoursite.com/2020/01/20/ggplot-pie-chart/","excerpt":"说到数据可视化，就逃不了饼图。我还记得在学校里做 presentation 的时候，饼图大概是最常见的图片类型。 这篇文章介绍怎么用 ggplot 做饼图。 \b\b","text":"说到数据可视化，就逃不了饼图。我还记得在学校里做 presentation 的时候，饼图大概是最常见的图片类型。 这篇文章介绍怎么用 ggplot 做饼图。 \b\b 别用饼图其实，饼图是糟糕的数据可视化方法，别用饼图。 原因：饼图用面积表示数量的大小，但视觉对面积的感知能力很弱，使用饼图会导致较低的信息传递效率。 先看下面这个饼图： 上面这个图让人有至少两个困惑： 第2和第4位是不是一样多呢？ 第1位到底比第2位多多少呢？ 一个更好的可视化，是使用柱状图： 柱状图符合人类进化的结果：眼睛对长度的敏锐度远远高于面积。 Less is More有的时候，我们可能想通过饼图强调某一个分类的占比最大。其实这里也可以用柱状图。 先看下图： 使用饼图已经足够给人困扰了，使用3D形式简直就是在犯罪。 看看Joey Cherdarchuk的优化成果： 清晰，简洁，美观，舒服。 Joey Cherdarchuk 的原文一步步把前面那个丑陋的饼图简化成了后面的样子，非常震撼。 如何用 ggplot 做饼图回答最开始提出的问题，如何用 ggplot 做饼图呢？答案：别做饼图，改用柱状图。 如果你真的非饼图不画，ggplot 可能不是个好工具。饼图的缺点基本已经是统计学届的共识，所以 ggplot 完全没有提供制作饼图的 geom_pie。 当然，ggplot 灵活的语法还是可以画出饼图的，可以先用geom_bar，然后做一个坐标变换coord_polar。具体代码可以参考这里。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据可视化","slug":"数据可视化","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"Python OOP 之 Property","slug":"python-property","date":"2020-01-20T01:54:12.000Z","updated":"2020-01-22T19:42:39.787Z","comments":true,"path":"2020/01/20/python-property/","link":"","permalink":"http://yoursite.com/2020/01/20/python-property/","excerpt":"今天学习 Python OOP 编程的一个 interface：property。 OOP 编程有两个常用的概念：getter 和 setter。Property 装饰器是 Python 实现 getter 和 setter 的方式。 这篇文章用一个例子说明如何使用 property。 \b","text":"今天学习 Python OOP 编程的一个 interface：property。 OOP 编程有两个常用的概念：getter 和 setter。Property 装饰器是 Python 实现 getter 和 setter 的方式。 这篇文章用一个例子说明如何使用 property。 \b \b业务代码 v1背景：初出茅庐的你，在为公司写一个记录员工信息的系统。 第1版系统里需要记录员工的姓名和收入。 员工可以用一个 class 表示，每个 instance 都包含员工的姓名和收入。 初步掌握 OOP 编程的你，很快完成了第1版代码： 1234567891011121314class Person(): def __init__(self, name, income): self.name = name self.income = income def __repr__(self): return f'Person {self.name} with income {self.income}'Tom = Person(name = 'Tom', income = 3000)print(Tom) # Person Tom with income 3000Tom.income = 5000print(Tom.income) # 5000 然后老板提出了一个需求：我们是社会主义国家的企业，为了体现社会主义的先进性，员工工资只能增加，不能减少，你要把这个特点写到系统里。 这个神奇的需求当然很容易实现，不需要修改 Person 这个对象的代码，只需要在客户端用 POST 方法修改工资时做一个条件判断，这个需求大概只需要3分钟完成。 可是，你仔细思考了老板的话，如果只是在 Restful API 上做检查，岂不只是“表面文章”，社会主义的先进性，难道不是应该体现在 object 层面吗？ 于是，你决定实现一个功能：修改 income 时，如果 income 不增加，会报错。 测试逻辑除了实现老板的需求外，你还有另一个追求：你希望 Person 对象的 API 不会改变，也就是说，新版本的 Person 对象会实现对低版本的兼容。 完成新的Person后，你要做两个测试。 第1个测试： 12345Tom = Person(name = 'Tom', income = 3000)print(Tom) # Person Tom with income 3000Tom.income = 5000print(Tom.income) # 5000 上面这段代码的运行结果，要跟第1个版本一样。 第2个测试： 123Tom = Person(name = 'Tom', income = 3000)Tom.income = 1000 在运行到Tom.income = 1000时，会报错。 业务代码 v2然后，你开始研究怎么实现新的需求。聪明的你很快发现，Property 是实现上述需求的好方法。 新版本代码如下： 1234567891011121314151617class Person(): def __init__(self, name, income): self.name = name self._income = income #第4行 @property #第6行 def income(self): return self._income @income.setter #第10行 def income(self, value): if value &lt; self.income : raise ValueError(\"收入不能减少\") self._income = value def __repr__(self): return f'Person {self.name} with incom {self.income}' 我们依次查看这段代码里的新东西。 第4行：self._income = income这里用 _ 表示 private variable。 Python 其实没有真正的 private variable。下面这段代码会正常返回 _income。 1234567class Person(): def __init__(self, name, income): self.name = name self._income = income Tom = Person(name='Tom', income = 3000)print(Tom._income) # 打印出 3000 使用 _ 表示 private variable，其实是一种约定俗成。Python 有非常多的约定俗成，比如 class 里的self，其实也可以用其他字段代替。 第6行：@property@property 装饰器把 income 变成了一个 getter。 12345# ....省略 class 的代码Tom = Person(name='Tom', income = 3000)print(Tom.income) # 打印出 3000 此时我们不需要使用Tom._income，只需要像第1版一样用Tom.income就能获取 _income的内容。 如果没有@property装饰器，income就变成了一个方法，只能用Tom.income()的方式调用。 第10行：@income.setter这是 setter 装饰器，把下面的函数变成了 income 的 setter。 setter 这个名称很直观，我们会在满足条件后设置 income 的值。 在之后的函数里，我们检查了新的值是否小于原先的 income，如果不满足条件，我们就 raise 一个错误。 小结一顿操作后，第2版的业务代码使用 property 实现了老板的需求和 API 的兼容。非常完美。 参考 Geeksforgeeks: Python | property() function Programiz : Python @property document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Coding","slug":"Coding","permalink":"http://yoursite.com/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"理解 JavaScript 的 this","slug":"js-this","date":"2020-01-19T16:53:05.000Z","updated":"2020-01-22T19:42:39.783Z","comments":true,"path":"2020/01/19/js-this/","link":"","permalink":"http://yoursite.com/2020/01/19/js-this/","excerpt":"12345678var myObject = { name: 'Harry Potter', myMethod: () =&gt; { console.log(this.name) }}myObject.myMethod() // undefined 上面这段代码为什么会返回undefined呢？因为万恶的this。 MDN 对 this 的定义是：代码运行的环境。这句话给我的最大感觉是：what the ** is this? 这里总结下 this 的几个用法。 \b","text":"12345678var myObject = { name: 'Harry Potter', myMethod: () =&gt; { console.log(this.name) }}myObject.myMethod() // undefined 上面这段代码为什么会返回undefined呢？因为万恶的this。 MDN 对 this 的定义是：代码运行的环境。这句话给我的最大感觉是：what the ** is this? 这里总结下 this 的几个用法。 \b Default Binding在 Chrome 浏览器打开 inspector 的 console，输入如下代码： 12345var count = 5function Func() { console.log(this.count)}Func() console 会显示5。 因为我们的代码在环境下运行，this 默认绑定到了全局环境。 在use strict模式下，默认绑定不会发生。 123456var count = 5function Func() { `use strict` console.log(this.count)}Func() 此时 Chrome 会报错。 Implicit Binding在 object 里创建函数时，运行函数时的\bthis就是这个对象。 12345678var anObj = { name: 'Harry Potter', callName: function() { console.log(this.name) }}anObj.callName() 此时屏幕会打印 Harry Potter。 Explicit Binding如果不想在 object 创建函数，我们可以手动把函数的this绑定到对象上。 可以使用bind、call或apply。 12345678910111213var anObj = { name: 'Harry Potter',}function callName() { console.log(this.name)}callName.call(anObj) // Harry PottercallName.apply(anObj) // Harry PotternewCallname = callName.bind(anObj)newCallname() // Harry Potte call 和 apply 可以直接以 object 作为 argument。bind 需要指向一个新的变量。 new Binding创建 class 的 instance 时，this 会指向这个 instance 12345678910111213141516class Point { constructor(x, y) { this.x = x this.y = y } showCoord() { console.log(this.x + ', ' + this.y) }}p1 = new Point(1, 2)p1.showCoord() // 1, 2p2 = new Point(3, 4)p2.showCoord() // 3, 4 每个 instance 都会有自己的 context。 箭头函数箭头函数的this跟普通函数不一样，箭头函数会继承 parent scope 的this。 12345678910var name = 'Ron Weasley'var myObject = { name: 'Harry Potter', myMethod: () =&gt; { console.log(this.name) }}myObject.myMethod() // Ron Weasley 在上面这段代码里，我们用箭头函数定义了 myMethod，\b\b结果屏幕打印的是 global context 里的 name，因为 myObject 位于 global context。 如果是在use strict下，上面这段代码会打印undifined。 所以，谨慎在箭头函数里使用this，非常容易出错啊。 既然不能使用箭头函数，上面这段的代码要怎么写才更简洁呢？用 ES6 的函数写写法： 12345678var myObject = { name: 'Harry Potter', myMethod() { console.log(this.name) }}myObject.myMethod() // Harry Potter 搞清楚上面这些用法后，this 就没那么奇怪了。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Coding","slug":"Coding","permalink":"http://yoursite.com/categories/Coding/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yoursite.com/tags/JavaScript/"}]},{"title":"为什么数据团队应该采用 reproducible research","slug":"reproducible-research","date":"2020-01-19T10:07:01.000Z","updated":"2020-01-22T19:42:39.787Z","comments":true,"path":"2020/01/19/reproducible-research/","link":"","permalink":"http://yoursite.com/2020/01/19/reproducible-research/","excerpt":"Reproducible research （可重复研究）是学术界的一个潮流。它的意思是，所有研究都应该是可以“复制”的。如果你给我一个研究报告，你不能只给我看结果，你还要给我看到整个分析过程，而且我能够在自己的电脑上复制出同样的结果。 经历过几个公司的数据相关业务后，我深深地感觉到：这个规范不只应该用在科学研究里，它也应该用在商业公司的数据团队里。 \b","text":"Reproducible research （可重复研究）是学术界的一个潮流。它的意思是，所有研究都应该是可以“复制”的。如果你给我一个研究报告，你不能只给我看结果，你还要给我看到整个分析过程，而且我能够在自己的电脑上复制出同样的结果。 经历过几个公司的数据相关业务后，我深深地感觉到：这个规范不只应该用在科学研究里，它也应该用在商业公司的数据团队里。 \b 传统的分析报告为了简化讨论，我们假设数据已经自动搜集并存储在数据仓库中。我们先不讨论研究团队需要自己搜集数据的情况。 \b产品经理想了解一个问题：“我们为提升用户留存设计了一个新功能，这个新功能已经上线了1个月，它是否有效果呢？” 某分析师做了如下操作： 从数据库提取数据，或从数据后台“下载”数据 把数据导入 excel 中，开始清洗数据 做某些假设检验、或模型分析 把分析结果展示在 excel 中，或另外写一份 word 报告 在某些公司里，上面的做法已经“足够”了。但是，经历过学术训练的人会有如下问题： 怎么判断报告作者使用了“正确”的数据源？例子：提取数据的时候日期搞错了。 怎么判断作者正确清洗了数据？例子：float 变 int。 怎么判断作者做了需要做的检验？例子：使用 lm 模型却没检查假设是否能被满足。 怎么判断作者没有为了推销自己的结论而“调整”数据？例子：选择性展示数据。 …… 上面这些问题可以总结为：怎么知道分析师没有犯错，无论是有意的错误还是无意的错误。 按照传统的方法，“找分析报告的 bug”是个成本很高的活儿，我们几乎只能被动接受分析师给的结果。 这意味着，我们没有办法系统性地保证数据分析的质量。一个小公司也许可以容忍这样的错误可能，但对严重依赖数据做出决策、并且需要做出大量决策的公司，这不是最优解。 一个可复制的分析报告用可复制的分析报告，之前的研究问题会用下面的方法做。 数据获取要求：数据的获取必须调用 API 或者写 SQL 语句。 作用： 当我拿到你的分析，我能复制这段代码，然后调出完全一样的数据 如果我怀疑数据提取过程有问题，我可以检查代码，判断是不是取数据的代码写错了 禁止行为：在后台“下载”数据。没人知道你在下载前做了哪些操作。 \b数据清洗要求： 清洗数据必须使用代码完成。 整个数据清洗流程，都用注释清晰的标注。 作用：其他人能检查整个分析流程，判断是否有某些地方出错。 禁止行为：在 excel 或其他工具上用鼠标点选完成数据清洗。鼠标点选也是不可复制的，不只别人复制不了，分析师自己都很难复制（也许第一次分析时点错了某个地方却不自知）。 数据分析过程要求： 需要给出使用某个分析模型的原因 需要说明参数选择的过程 需要用代码展示完整的分析流程 作用： 数据分析包含一定的理论知识，也包含很多相对主观的判断，记录这些判断过程，有助于其他人理解 方便检查代码正确情况 禁止行为：不能把数据分析的过程当成“黑箱子”，过程和结果同样重要。 报告形式要求： 核心分析内容和分析结论在报告主干部分 从数据获取到分析部分的代码，都在备注部分，或者放在另一个文件里 作用： 报告使用者只需要阅读主要部分 报告审阅者可以在备注部分查找可复制研究的过程 工具目前似乎只有2个选择： R：使用 Rmarkdown Python：使用 Notebook 其他工具满足不了“可复制”的需求。 “可复制研究”的意义本质上，“可复制研究” 把数据分析从黑箱子变成了可以审阅的文本，发现分析错误变得相对便宜。 它让每个人的工作都变得 accountable。\b每一行代码、每一个分析决策，都被暴露在光天化日之下，\b东郭先生就无处藏身了。想象一下，写了你名字的报告上竟然有低级的数据清洗错误，\b这是件多么丢人的事情。 整体上，“可复制研究”会提高整个数据团队的分析质量。 我还没有机会在这样的团队工作，但过去的经历让我知道“普通”的数据分析团队可以糟糕到什么程度。看到某些分析师的报告，会让你怀疑他们是否上过统计学入门课，我一直为使用这些报告的决策者捏把汗。 可复制研究也对团队成员的能力有巨大的要求： 必须会 R 或 Python，会还不够，还必须能写出 readable code 表达能力要足够强 有一定的统计基础，能够做到引用文献 所谓“可复制研究”，除了是一种理念，还是一套工作流 workflow。就像 readable code 能整体上提高团队的开发质量，reproducible report 能整体上提高团队的数据分析质量。 \b使用可复制研究还有一个好处，“知识”变得可以沉淀，不再只是某些分析师脑子里的经验。后来者可以通过前人的报告学习分析思路、复用代码。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据科学","slug":"数据科学","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"}],"tags":[]},{"title":"JavaScript 其实很像 Python","slug":"js-python","date":"2020-01-18T12:21:29.000Z","updated":"2020-01-22T19:42:39.783Z","comments":true,"path":"2020/01/18/js-python/","link":"","permalink":"http://yoursite.com/2020/01/18/js-python/","excerpt":"在我刚入门 JavaScript 的时候，感觉 JavaScript 是个莫名其妙的语言。在那之前，我真正称得上了解的语言只有 python。写 python 是一种享受，相比之下，写 JavaScript 的体验很“怪异”。 后来我才直到，JavaScript 是一个在很短时间内创造的语言，是为了在浏览器上运行。我所学习的 JavaScript，还是20多年前的版本。拿老版本的 JavaScript 和今天的 python3 去比较，是挺不合理的。 在了解到最新的 JS 功能后，JavaScript 突然变得“可爱”了，甚至在某些地方很像 python。 \b\b\b\b\b","text":"在我刚入门 JavaScript 的时候，感觉 JavaScript 是个莫名其妙的语言。在那之前，我真正称得上了解的语言只有 python。写 python 是一种享受，相比之下，写 JavaScript 的体验很“怪异”。 后来我才直到，JavaScript 是一个在很短时间内创造的语言，是为了在浏览器上运行。我所学习的 JavaScript，还是20多年前的版本。拿老版本的 JavaScript 和今天的 python3 去比较，是挺不合理的。 在了解到最新的 JS 功能后，JavaScript 突然变得“可爱”了，甚至在某些地方很像 python。 \b\b\b\b\b 多行 string问题：如何给 string 换行呢？ python123poem = \"\"\"Programming is funExcept for syntax errorsMissing curly brace\"\" 老版本的 JavaScript 不支持，但现在支持了： JavaScript123var poem = `Programming is funExcept for syntax errorsMissing curly brace`; Expression Interpolation问题：如何方便地在 string 中使用变量呢？ python123a = 5b = 10print(f'Fifteen is {a + b} and not {2 * a + b}.') 上面这个功能很实用，让代码的可读性提高了几个档次。JavaScript 也有类似的写法： JavaScript123var a = 5var b = 10console.log(`Fifteen is ${a + b} and not ${2 * a + b}.`) Destructuring问题：如何同时 assign 几个变量的值呢？ python12numbers = (1, 2, 3)x, y, z = numbers Destructuring 在某些场合有用，ES2017 里有了类似的设计： JavaScript12var numbers = [1, 2, 3]var [x, y, z] = numbers Spread Operator问题：如何 assign 数组里的一个变量，并忽略其他变量呢？ python12numbers = [1, 2, 3, 4]first, *remaining = numbers 下面是 JavaScript 的写法： JavaScript12var numbers = [1, 2, 3, 4]var [first, ...remaining] = numbers Rest Operator问题：如何给函数任意多个 argument 呢？ python12345def myFun(*argv): for arg in argv: print (arg)myFun('a', 'b', 'c') 在 python 里这个规则叫 wargs。在 JavaScript 里，使用 ...，这三个点叫 *rest operator JavaScript12345678function product(...args) { var arg for (arg of args) { console.log(arg) }}product('a', 'b', 'c') 箭头函数问题：如何把一个数组里的数字全部开方 python1234numbers = [1, 2, 3, 4]list(map(lambda x: x * 2, numbers))# or [x * 2 for x in numbers] JavaScript 里使用箭头函数：=&gt; JavaScript12var numbers = [1, 2, 3, 4]numbers.map(v =&gt; v * 2) 相比 lambda，箭头函数甚至更加 elegant。 Class问题：如何创建一个 class python123456class Point: def __init__(self, x, y): self.x = x self.y = y def __str__(self): return \"({x}, {y})\".format(x=self.x, y=self.y) 在 ES2017 之前，JavaScript 的做法： JavaScript12345678function Point(x, y) { this.x = x this.y = y}Point.prototype.toString = function () { return '(' + this.x + ', ' + this.y + ')';}; 第一次看到上面这段代码时我非常费解，这是什么鬼😰？现在有新的写法了： JavaScript12345678910class Point { constructor(x, y) { this.x = x; this.y = y; } toString() { return '(' + this.x + ', ' + this.y + ')'; }} 习惯 python 的开发者可以无缝理解了😆。 小结在 Hacker News 上看到过一句话： 我招人的时候从来不问对方会什么编程语言，因为只要你会一门语言，掌握其他语言都很容易。作为一个工程师，真正重要的不是你会什么语言或框架，而是…… 这句话我只记得前半句，现在有点理解为什么编程语言不重要了。不过重要的到底是什么呢？虽然我不是软件工程师，不过还是对这个答案很好奇。 如果我需要招一个软件工程师，我会希望他/她有什么特质？ document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Coding","slug":"Coding","permalink":"http://yoursite.com/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"},{"name":"JavaScript","slug":"JavaScript","permalink":"http://yoursite.com/tags/JavaScript/"}]},{"title":"机器学习 vs. 统计学","slug":"statistics-ml","date":"2020-01-18T07:47:56.000Z","updated":"2020-01-22T19:42:39.787Z","comments":true,"path":"2020/01/18/statistics-ml/","link":"","permalink":"http://yoursite.com/2020/01/18/statistics-ml/","excerpt":"机器学习和统计学不是一回事，可是机器学习里和统计学里又有很多交集，比如线性回归。两者都使用了相同的理论框架，但强调的东西完全不一样。 在具体的公司业务场景中，我们需要明确，自己需要的到底是统计学，还是机器学习。两者会对分析场景有不同的需求。 这篇文章总结两个学科的需求。 \b","text":"机器学习和统计学不是一回事，可是机器学习里和统计学里又有很多交集，比如线性回归。两者都使用了相同的理论框架，但强调的东西完全不一样。 在具体的公司业务场景中，我们需要明确，自己需要的到底是统计学，还是机器学习。两者会对分析场景有不同的需求。 这篇文章总结两个学科的需求。 \b 统计学统计学至少有两个典型的使用场景： 使用样本估计总体 建立解释性模型 样本估计总体问卷调查是公司了解用户的重要手段。我最喜欢的例子是乐高。2004年时，乐高亏损严重。乐高的美国分公司老大跟《星球大战》的版权方谈妥了合作意向，于是飞到丹麦总部跟公司提出这个方案。乐高公司的高层对这个提议非常“震怒”，因为这违背了乐高一直以来“反对暴力”的理念：乐高的产品里一定不会有暴力元素，更别说要出一个名字里带“war”的产品系列了。 提出这个方案的美国老大动用了一个杀手锏：要不我们对家长做个问卷调查，看看家长们是否愿意为孩子们购买星战题材的乐高。问卷调查的结果说服了保守的乐高高层。《星球大战》系列开启了乐高的新时代，乐高开始频繁与全球大IP合作，各大 IP 为乐高带来了持续十几年的高速增长。 这里的问卷调查，其实就是统计学的重要应用：问卷调查的样本数据是整体市场数据的有效代表吗？把这个问题更抽象地表达：我只有 x 个样本，我是否能用这 x 个样本去有效的估计总体。 商业调查可以通过花钱解决样本数量问题，毕竟一份问卷也没多贵，但在医学药物实验里，一个样本就没那么便宜了。一轮药物实验经常只有几十个样本。用这几十个样本去估计总体，难度要大得多。 在互联网公司，最经常使用的统计学的场景是 A/B 测试，这里的核心问题是：A/B 测试的样本数据，是有效的总体代表吗？换句话说，我们可以通过这几千个样本，判断 A 版本比 B 版本更好吗？ 建立解释性模型社会科学的论文需要利用统计学证明自己想描述的理论关系。 比如： 收入的决定因素是什么？ 是否存在收入上的性别/种族歧视？ \bR&amp;D投入和市场投入对公司长期盈利能力的影响分别有多大？ …… 所有这些问题，都需要建立一个模型去描述现象，然后通过数据验证这个模型的准确性。这里既存在样本代表性的问题（样本估计总体），还有模型解释力的问题。 比如在线性回归里，我们关注 R-square，一个好的模型，应该有比较好的 R-square。同时，这个模型应该是“可解释”的。相比机器学习，\b统计学的模型不能是个“黑箱子”。机器学习可以接受模型的“不可解释”，统计学则要求模型 make sense。 机器学习机器学习与统计学有两个大的区别： 大样本 以预测为目的 大样本统计学里有100个样本可能就是很大了，一个 excel 表格就能轻松装下。机器学习利用了互联网时代的数据爆发，有海量的数据可供使用。实际上，机器学习已经存在了几十年，但因为没有足够“喂养”模样的数据和算力，一直没能发展，直到互联网时代。 统计学需要考虑“样本少”的问题，机器学习不只不用担心样本量，有时甚至能用“总体”做计算。 在大数据的前提下，很多统计学需要担心的问题不存在了。比如小样本下不适合使用某些 test。 以预测为目的机器学习的最核心特征，是以预测为目的，预测准确度越高越好，过程并不重要。 机器学习不关心模型的解释效力。注意，这里说的是”不关心“。有的模型，比如线性回归，允许人对模型过程做解释，但另外一些模型，比如神经网络，很难解释。 在应用层面，机器学习非常的“务实”：别跟我扯理论，show me the accuracy。 同样是线性回归，即使用同样的数据集，我们也可能因为目标而不同而有各自的侧重。想象我们是一家连锁蛋糕公司，旗下有100家店铺。我们搜集了过去几年这些店铺的人流量、营业收入、商圈竞争对手数量等信息。我们可以： 研究哪些因素最影响营业收入。 预测这些店铺未来的收入。 上面两个任务都是可以用线性回归来做，但前者会偏重统计学，需要解释力，后者会偏重机器学习，需要预测力。 如何选择技能点单纯的统计学使用者，可以选择忽略机器学习。统计学使用者包括： 社会科学领域的学者 咨询公司的数据分析师 大公司的用户调查团队 医药学研究者 … 数据工作者成千上万，真正有机会用到机器学习解决问题的并不多。 但是，在互联网公司工作的数据工作者，或者希望在互联网公司做数据工作的人，大概率有机会使用机器学习，这个时候了解机器学习就会非常必要了。从学科脉络来看，机器学习的部分理论基础就是统计学，所以搞机器学习的人，是逃不过学习统计学的。所以，如果你想再互联网公司做数据工作，统计学和机器学习都是要有所了解的。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据科学","slug":"数据科学","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"Python 的 Generator","slug":"python-generator","date":"2020-01-17T13:52:13.000Z","updated":"2020-01-22T19:42:39.787Z","comments":true,"path":"2020/01/17/python-generator/","link":"","permalink":"http://yoursite.com/2020/01/17/python-generator/","excerpt":"问题：x 是一个由数字组成的 list，我们想求出每个元素的平方。 一个解决方法是： 12345678def square_numbers(nums): result = [] for i in nums: result.append(i * i) return resultmy_nums = square_numbers([1,2,3,4])print(my_nums) # [1, 4, 9, 16] 这是个正确的答案，但不完美。我们可以使用 generator 写出更简洁的答案： 123456def square_numbers(nums): for i in nums: yield(i * i)my_nums = square_numbers([1,2,3,4])print(list(my_nums)) \b","text":"问题：x 是一个由数字组成的 list，我们想求出每个元素的平方。 一个解决方法是： 12345678def square_numbers(nums): result = [] for i in nums: result.append(i * i) return resultmy_nums = square_numbers([1,2,3,4])print(my_nums) # [1, 4, 9, 16] 这是个正确的答案，但不完美。我们可以使用 generator 写出更简洁的答案： 123456def square_numbers(nums): for i in nums: yield(i * i)my_nums = square_numbers([1,2,3,4])print(list(my_nums)) \b generator 函数普通的函数使用 return 返回结果，generator 函数使用 yield 返回结果。 generator 函数可以使用 next() 获取下一个返回值。 1234567891011def dumb_generator(): yield 1 yield 2 yield 3a = dumb_generator()print(next(a)) # 1print(next(a)) # 2print(next(a)) # 3print(next(a)) # 报错：StopIteration 上面这段代码会在运行next(a)依次返回1、2、3，然后报错。 我们可以直接把 generator 函数的返回对象用在 for loop 里： 123456789def dumb_generator(): yield 1 yield 2 yield 3a = dumb_generator()for i in a: print(i) for loop 在完成循环后会自动停止，不会报错。 generator comprehension文章最开始的问题，其实可以用 list comprehension 快速解决： 1my_nums = [x * x for x in [1,2,3,4]] generator 也可以用 comprehension 的形式快速生成： 1my_nums = (x * x for x in [1,2,3,4]) # 这是一个 generator 为什么使用 generator除了方便之外，generator 还有什么好处呢？最大的好处是，节约内存。 假设生成从1到100万的 list，这个 list 会被存在内存里，占据大量空间。如果生成从1到100万的 generator，内存占用量几乎可以忽略不计。 另外，generator 还可以用来表达数学上的无穷数列，比如 Finabocci 数列。 12345678910def fib(): a, b = 0, 1 while 1: yield a a, b = b, a + bfor i in fib(): print(i) if i &gt; 1000: break 上面的代码会打印出从0开始的 Finabocchi 数列，直到数列大于1000（第18个数字就会大于1000）。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Coding","slug":"Coding","permalink":"http://yoursite.com/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"决策树模型里的 Entropy","slug":"decision-tree-entropy","date":"2020-01-17T07:06:33.000Z","updated":"2020-01-22T19:42:39.779Z","comments":true,"path":"2020/01/17/decision-tree-entropy/","link":"","permalink":"http://yoursite.com/2020/01/17/decision-tree-entropy/","excerpt":"决策树模型是机器学习的重要模型。决策树里有个概念，叫 entropy，模型的最优化函数基于 entropy 做出。 用一个诗意的说法，entropy 描述了世界的混乱程度。Split 能帮助降低混乱程度。 这篇文章用具体例子说明，split 如何降低 entropy。 \b","text":"决策树模型是机器学习的重要模型。决策树里有个概念，叫 entropy，模型的最优化函数基于 entropy 做出。 用一个诗意的说法，entropy 描述了世界的混乱程度。Split 能帮助降低混乱程度。 这篇文章用具体例子说明，split 如何降低 entropy。 \b 公式给定数据集中有 C 个分组，entropy 的公式如下： 公式中的 pi 是第 c 类元素的出现概率。 不可知与可知想象一个世界上只有“好人”，那么好人的概率是1。因为 log_2(1) = 0，此时的 entropy = 0。 想象另一个世界，只有坏人，那么好人的概率是0，这时 entropy = -1 * 0 * log_2(1) = 0。 上面两种情况，如果以 entropy 来描述，都是“可知”的，不存在任何混乱，这是个稳定的世界。 想象第3个世界：好人和坏人各占一半，那么 entropy = (0.5 * log_2(0.5)) + (0.5 * log_2(0.5)) = 1。 这是个极端“混乱”的世界，路上随便碰到一个人，你完全不知道他是好人还是坏人。在这里，不确定性达到最大值。 引入解释变量我们还在第3个世界里，作为数据工作者，我们无法忍受这种混乱，于是我们决定建立一个模型，找到识别坏人和好人的方法。 我们去警察局获取了100个人的档案，其中有50个好人、50个坏人。档案里还有另一个数据：是否染发。 根据上面的档案数据，我们绘制表格如下： 我们似乎可以用染发与否判断一个人是好人还是坏人。 如果使用上面的判断方式，我们的 entropy 会减少多少呢？ E(染发) = 10/45 * log_2(10/45) + 35/45 * log_2(35/45) = 0.76E(不染发) = 40/55 * log_2(40/55) + 15/55 * log_2(15/55) = 0.85 然后按照频率加权平均，得到以染发预测好人的 entropy：E(是否好人｜是否染发) = 45/100 * 0.76 + 55/100 * 0.85 = 0.81 现在我们看到一个染发者，就判断他是坏人，然后躲得远远的。我们会有一定的错判率（大概29%），但这已经比之前无法判断的情况有了进步，这个世界没有那么混乱了。怎么衡量混乱程度的减少呢？我们用原先的 entropy 减去基于某个因素做判断的 entropy，得到这个因素的 information gain： IG= = E(是否好人) - E(是否好人|是否染发) = 1 - 0.81 = 0.19 引入染发这个 split，我们获得了 0.19 的进步。 如果我们有更多变量，我们就可以依次计算每个变量的 IG，并选择 IG 效果最好的变量作为解释变量。当我们依次选择出了若干个解释变量，所谓的决策树🌲就出现了。 一个引申如果公司对 A 方案有5成把握，在 entropy 函数里，混乱程度是最严重的。另外一个方案 B，公司只有2成把握，这时的 entropy 值比较低。 这是一个有意思的发现：我们希望 entropy 越低越好。站在公司角度，B 方案是个可以快速拒绝的方案：我们清楚地知道它大概率失败（假设两个方案的预期回报相等）。真正造成混乱后果，往往是 A 方案这样模棱两可的方案。 再看一个（半搞笑的）场景，假设有两个同事： A 员工的判断准确度是50% B 员工的判断准确度是20% 我会更希望自己的手下是哪个呢？按照 entropy 公式，B 员工的 entropy 值更低。此时我们选择 B 员工：我们只要做出跟 B 员工的判断相反的选择，就大概率正确了。而 A 员工呢，价值还不如一枚硬币，毕竟通过抛硬币做选择也能达到50%的准确度。 现实生活里有没有类似 B 员工的人呢？可能没有这样的人，但在某一类问题上，有人开能会习惯性犯错。 我曾经有个同事喜欢追求完美，总是没有办法按期完成任务，ta 经常会说“我觉得这个版本还不够好/我还没准备好，要不再等一等”。如果选择延期，结果往往更糟糕。在按期交付问题上，ta 的判断力就像只有20%的准确度 😂。当我意识到这点后，每次 ta 提出“可以延期“时，我总会立刻做出判断：不能延期了，必须交付。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"统计理论","slug":"统计理论","permalink":"http://yoursite.com/categories/%E7%BB%9F%E8%AE%A1%E7%90%86%E8%AE%BA/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"}]},{"title":"线性回归的假设","slug":"lm-assumptions","date":"2020-01-16T12:56:06.000Z","updated":"2020-01-22T19:42:39.783Z","comments":true,"path":"2020/01/16/lm-assumptions/","link":"","permalink":"http://yoursite.com/2020/01/16/lm-assumptions/","excerpt":"数据可以骗人，这个道理大家都知道。我印象最深的经历是：同事给了一个基于 linear regression 的研究报告，但报告完全没有对线性回归的假设做任何诊断。不做假设检验的分析报告在大学作业里会被判断为不及格。 但这份报告在业务部门中传阅，成为了产品的决策依据。这是一个上市公司，报告分析的产品也是公司的现金牛产品。 糟糕的数据分析，最好的结果是浪费了大家的时间，最坏的结果是指导决策者做出错误的决策。 这篇文章小结一下 linear regression 的几个核心假设，就当是大学知识的一次复习。 \b\b\b\b\b","text":"数据可以骗人，这个道理大家都知道。我印象最深的经历是：同事给了一个基于 linear regression 的研究报告，但报告完全没有对线性回归的假设做任何诊断。不做假设检验的分析报告在大学作业里会被判断为不及格。 但这份报告在业务部门中传阅，成为了产品的决策依据。这是一个上市公司，报告分析的产品也是公司的现金牛产品。 糟糕的数据分析，最好的结果是浪费了大家的时间，最坏的结果是指导决策者做出错误的决策。 这篇文章小结一下 linear regression 的几个核心假设，就当是大学知识的一次复习。 \b\b\b\b\b LM的假设 线性关系 自变量之间不具有多重共线性 扰动项符合正态分布 同方差 没有自相关：这种情况在非时间序列里很少见，所以我们不讨论了 1. 线性关系第一个假设最直接：\b\b\b自变量和因变量之间是线性关系。 反例：y = a + b * x ^ 3，这里的 y 和 x 就不是线性关系。 做一元回归时，散点图可以揭示自变量与因变量之间的关系。 如果是多元回归，可以使用 R 的 lm 对象自带的 plot 函数。函数返回的第1个图片：Residuals vs Fitted 能够用来检查线性假设。 我们模拟数据并示例如下： 12345678910111213141516size &lt;- 30x &lt;- rnorm(size, 15, 10)y1 &lt;- 3 + 5 * x + rnorm(size, 5, 3)y2 &lt;- 3 + 5 * x^3 + rnorm(size, 5, 3)fit_1 &lt;- lm(y1 ~ x)fit_2 &lt;- lm(y2 ~ x)p1 &lt;- autoplot(fit_1)p2 &lt;- autoplot(fit_2)p1_1 &lt;- p1[[1]] + ggtitle('满足线性假设') + theme(plot.title = element_text(size = 18))p2_1 &lt;- p2[[1]] + ggtitle('不满足线假设') + theme(plot.title = element_text(size = 18))ggarrange(p1_1, p2_1 + rremove('y.title'), ncol = 2, nrow = 1) 我使用了 ggfortify 包处理 lm 的图片，并用 ggpubr 包把两个模型的图片并列在一起。 图片如下： 当模型满足线性假设时，fitted value 和 residuals 的关系接近一条直线（如左图），右图则明显不是直线。 2. 多重共线性要求：自变量之间没有过于强的线性关系。 有一些线性关系是没问题的。在研究现实问题时，我们很难找到完全没线性关系的自变量。 比如研究收入的影响因素，我们会考虑智商和学历。智商越高，自然收入越高；学历越高，当然收入也越高。可是，学历也同时跟智商有线性关系。这会是个问题吗? 只要这两个变量不是完全的线性关系，我们就不用担心。这两个因素当然不是完全线性关系，除了智商之外，家庭条件、考生的所处省份、个人兴趣等因素也跟学历有巨大关系。 我们可以查看所有自变量之间的相关性。ggplot 生态里有个非常好用的 ggcorrplot 包： 1234567library(ggcorrplot)data(mtcars)corr &lt;- round(cor(mtcars), 1)ggcorrplot(corr, hc.order = TRUE, type = \"lower\", outline.col = \"white\", ggtheme = ggplot2::theme_gray, colors = c(\"#6D9EC1\", \"white\", \"#E46726\")) 结果如下图： 如果想更严格地描述多重共线性问题，可以参考一个叫 variance inflation factor 的指标。 3. 扰动项符合正态分布扰动项 error term \b\b\b是一个理论概念：没有被观察到的影响因素，都算在扰动项里。扰动项无法直接衡量，所以我们用残差 residuals 来代替。残差是真实值和拟合值之间的差。 一般使用 Normal QQ 图来检查扰动项是否符合正态分布。 我们先 simulate 两组数据，然后对比它们的 QQ 图： 123456789101112131415161718size &lt;- 100x &lt;- rnorm(size, 15, 10)err &lt;- rnorm(size, 5, 3) y1 &lt;- 3 + 5 * x + erry2 &lt;- 3 + 5 * x + err ^ 3fit_1 &lt;- lm(y1 ~ x)fit_2 &lt;- lm(y2 ~ x)p1 &lt;- autoplot(fit_1)p2 &lt;- autoplot(fit_2)p1_2 &lt;- p1[[2]] + ggtitle('扰动项正态分布') + theme(plot.title = element_text(size = 18))p2_2 &lt;- p2[[2]] + ggtitle('非正态分布') + theme(plot.title = element_text(size = 18))ggarrange(p1_2, p2_2 + rremove('y.title'), ncol = 2, nrow = 1) 我们让第1个模型的扰动项完美符合正态分布，让第2个模型第扰动项严重偏离正态分布。得到的 QQ 图如下： 在完美假设的情况下，所有的点几乎跟图中直线重合。右图中的点则严重偏离了图中直线。 4. 同方差同方差假设的内容是：对不同的自变量值，扰动项的方差是相同的。如果违反了这个假设，就叫“异方差”。 典型的的异方差场景：研究收入和学历的关系，我们可以大概预料到，学历越高的人，收入的反差越大（有的人混得非常好，有的人混得一般）。 这是线性回归里非常重要的假设，我们可以用 ncvTest() 检测异方差。也可以在做出模型后做可视化检查，即使用 scale-location 图。 跟之前的思路一样，我在下面的代码里模拟一个正常模型和一个异方差模型。 1234567891011set.seed(123)size &lt;- 100x &lt;- rnorm(size, 15, 10)err_1 &lt;- rnorm(size, 5, 3)err_2 &lt;- (x -1)* rnorm(size, 5, 3)y1 &lt;- 3 + 5 * x + err_1y2 &lt;- 3 + 5 * x + err_2fit_1 &lt;- lm(y1 ~ x)fit_2 &lt;- lm(y2 ~ x) 这里我们查看 scale-location 图，下图中同方差的情况是一条比较直的线，异方差则比较斜。 另一个更符合直接的参考图，是 x 和对应残差的散点图。参考下图：下图的异方差现象很明显，残差随着x的变大而变大。 小结线性回归模型的前提是模型满足假设，这是科学研究的规范，在公司里生成研究报告时，也应该做相应的检查。 在 R 语言里查看这几个假设很简单，只需要在 fit = lm(y ~ x)使用plot(fit)函数。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"统计理论","slug":"统计理论","permalink":"http://yoursite.com/categories/%E7%BB%9F%E8%AE%A1%E7%90%86%E8%AE%BA/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"AB测试的例子：访问时长","slug":"ab-test-length","date":"2020-01-16T03:46:52.000Z","updated":"2020-01-22T19:42:39.779Z","comments":true,"path":"2020/01/16/ab-test-length/","link":"","permalink":"http://yoursite.com/2020/01/16/ab-test-length/","excerpt":"上一篇关于AB测试的文章里，我们模拟了一个常见的 ab 测试场景：转化率。这个场景适用于计算百分比数据的场景。 还有一种场景，数据不是百分比，而是\b\b连续数值。例如： 访问时长 人均消费 人均阅读数量 … 这个问题场景下，不适合使用 r 的 prop.test 函数。我们可以使用 z-test。 \b","text":"上一篇关于AB测试的文章里，我们模拟了一个常见的 ab 测试场景：转化率。这个场景适用于计算百分比数据的场景。 还有一种场景，数据不是百分比，而是\b\b连续数值。例如： 访问时长 人均消费 人均阅读数量 … 这个问题场景下，不适合使用 r 的 prop.test 函数。我们可以使用 z-test。 \b 场景我们是一个内容 app，产品部门开发了一个新版本，我们想要测试新版本下的用户访问时长是否会提高。 我们的原假设和备择假设是： H0：新方案的访问时长 &lt;= 老方案的访问时长 Ha：新方案的访问时长 &gt; 老方案的访问时长 我们选择单侧检验有2个原因： 从产品迭代流程考虑，如果没有证据正面新方案比老方案好，我们就不会全面部署新方案，所以我们寻找证据“证伪”老方案 从统计功效考虑，使用单侧检验能在相同样本下保证更高的统计功效，也就是节约成本了 因为比较的是两个总体的分布是否有差距，我们使用 two sample t-test。 参数设定和样本数量估计跟之前一样，我们设定 80% 的 power 和 0.05 的 significance level。 t-test 的样本量估算需要先给定一个 cohen’d。 d = (m1 - m2 ) / delta，其中： m1 和 m2 分别是两组的均值 delta 是 common standard deviation \b\b在开始测试之前，我们只知道 m2 的时长，假设 m2 = 60。理论上我们不可能知道 delta，但我们可以用老方案的样本去估算。一个“便利公式”是 delta = （最大值 - 最小值）/4。假定 delta = 25。 现在，我们要判断：我们预期新方案的均值有多大的提升呢？假设我们期望新方案会比老方案提高5，也就是从60提高到65。这时我们可以计算 cohen’d = （65 - 60） / 25 = 0.2 这时我们可以用 R 的 pwr package 估算需要的样本量： 1pwr.t.test(d = 0.2, sig.level = 0.05, power = 0.8, type = 'two.sample', alternative='greater') 这个计算告诉我们，每个组需要310个样本。我们着手安排测试。 检查数据一天之后，我们搜集够了650个样本，每组325个样本，我们开始检查数据。 我们发现两个组的数据如下： 新方案：平均时长64秒，标准差43秒 原方案：平均时长60秒，标准差40秒 看上去新方案更好，但我们能得出新方案更好的结论吗？ 我们可以用 t.test 做检验： 1234x &lt;- rnorm(315, 64, 43)y &lt;- rnorm(315, 60 ,40)t.test(x, y , alternative = 'greater') 我在这里模拟了数据，实际上我们可以直接带入两个 list 进 t.test，或者用现成的能输入均值和标准差的函数。 结果：p值 = 0.21，我们无法拒绝原假设。 结论：新方案未必比老方案好，我们需要做进一步测试（增加样本量），或保留老方案。 另一个平行宇宙里，新方案的平均时长还是64秒，标准差是40秒，我们的结论又会变成怎样呢？ 1234x &lt;- rnorm(315, 64, 40)y &lt;- rnorm(315, 60 ,40)t.test(x, y , alternative = 'greater') p值 = 0.04956，小于 0.05。结论：我们拒绝原假设，认为新方案更好。 AB 测试不只关注均值，还关注分布我经常看到不了解统计学的同事用两个均值作为方案优劣的比较依据。上面的例子可以说明：均值差异是不够的。很多时候，我们观察到的均值差异只是随机现象的结果。 科学的方法还会考虑分布，怎么考虑分布呢？选择一个合适的 test 计算统计显著性。 不是每个人都懂统计学，但有的人会懂得尊重科学。 当我们从公司层面追求科学的数据方法论，公司从上到下的决策水平都会提高。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"增长黑客","slug":"增长黑客","permalink":"http://yoursite.com/categories/%E5%A2%9E%E9%95%BF%E9%BB%91%E5%AE%A2/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"AB测试的例子：转化率","slug":"ab-test-ctr","date":"2020-01-15T14:26:03.000Z","updated":"2020-01-22T19:42:39.779Z","comments":true,"path":"2020/01/15/ab-test-ctr/","link":"","permalink":"http://yoursite.com/2020/01/15/ab-test-ctr/","excerpt":"AB 测试是互联网产品优化的科学方法，甚至可能是唯一科学的方法。在这篇文章里，我用 R 语言模拟 AB 测试的\b流程。 \b","text":"AB 测试是互联网产品优化的科学方法，甚至可能是唯一科学的方法。在这篇文章里，我用 R 语言模拟 AB 测试的\b流程。 \b \b场景\b\b假设我们有一个购物 APP，我们重新设计了商品页面，现在我们要回答的问题是：新设计方案对用户的购买率有提高吗？令原方案为 A，新方案为 B。 我们的原假设和备择假设是： 原假设：新方案的转化率 &lt;= 老方案的转化率 备择假设：新方案的转化率 &gt; 老方案的转化率 因为我们只关心 B 方案是否会比 A 方案好，所以我们使用 one-sided test。原假设是我们想要通过数据去“证伪”的假设，所以原假设是“新方案是没有用处的”，即新方案的转化率低于或等于老方案。 因为需要判断的是转化率，我们可以使用 Z-test。 参数设定和样本数量估计在开始搜集数据前，我们需要\b设定几个参数。 \b显著性水平 significance level：我们愿意接受的犯第1类错误的概率是多少？ 统计功效 power：我们希望的统计功效是多少？ 给定当前的转化率（10%），我们希望 B 方案的转化率提高到多少？ 我们依次设定参数如下： 显著性水平 5% 统计功效 80% 转化率提高到 12% 我们假设样本会平均分配到两个方案中。 我们使用 pwr packag 来计算需要的样本量 1234pwr.2p.test(h=ES.h(p1 = 0.10, p2 = 0.12), sig.level = 0.05, power=0.8, alternative = 'less') 这个计算告诉我们，每组大概需要 3021 个样本，一共需要大约6100个样本。 根据 app 流量，我们预计1天的时间可以搜集完所有的数据。于是我们使用现成的工具（或者让工程师开发），并开始测试。 检查数据一天之后，我们搜集够了6100个样本，我们开始检查数据。 我们发现两个组的数据如下： 原始方案：3500个样本中，有360个用户发生了转化 新方案：3500个样本中，有400个用户发生了转化 看上去是新方案\b“获胜”了，可是，这个差异在统计学上显著吗？ 我们做一个使用 r 的 prop.test 函数： 1prop.test(x = c(360, 400), n = c(3500, 3500), alternative = 'less') 结果：p 值 = 0.067，比预先设定的显著性水平高，我们不能拒绝原假设。 结论：我们没有理由认为新方案更好。 想象再另一个平行宇宙，新方案有410个用户发生了转化，我们的 p 值会是多少呢？ 1prop.test(x = c(360, 410), n = c(3500, 3500), alternative = 'less') 结果：p 值 = 0.031，我们可以拒绝原假设了。 结论：新方案的转化率更高。 为什么是 80% 和 5%？在上面的例子中，我们选择了 80% 的 power 和 5% 的 significane level。为什么呢？Stackoverflow 的数据科学家给了一个非常好的解释。 如果选择95%的 power 和1%的 significance level，我们的结论准确度会有极大提高，但测试会消耗更多的时间，导致影响商业决策的效率。 如果我们在刚才的例子追求这样的准确度，我们需要的样本量会翻倍，也就是说，\b\b时间成本翻倍。 如果只看单个测试，翻倍似乎是可以接受的，但一个成熟的互联网产品可能在同时进行几十个优化测试，如果每个测试都追求极端准确性，产品的迭代速度会减少50%。对于“天下武功，唯快不破”的互联网产品，这样的效率损失是绝对不可接受的。 参考： 为什么使用单侧检验 pwr package document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"增长黑客","slug":"增长黑客","permalink":"http://yoursite.com/categories/%E5%A2%9E%E9%95%BF%E9%BB%91%E5%AE%A2/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"1类错误和2类错误","slug":"type-one-error","date":"2020-01-15T11:45:10.000Z","updated":"2020-01-22T19:42:39.787Z","comments":true,"path":"2020/01/15/type-one-error/","link":"","permalink":"http://yoursite.com/2020/01/15/type-one-error/","excerpt":"统计学里有两个基石一样的概念：一类错误和二类错误。这两个概念是统计检验的基础。 \b","text":"统计学里有两个基石一样的概念：一类错误和二类错误。这两个概念是统计检验的基础。 \b 原假设在定义这两类错误前，我们需要先复习假设检验。 在检验检验里，我们定义了原假设 null hypothesis。原假设是我们希望通过数据去“证伪”的假设，习惯被表述为 H0。 一个典型的 H0 是：本市的人均收入大于或等于8000元。 原假设的对立面，是备择假设 alternative hypothesis，习惯被表述为 Ha。 上面的 H0 对应的 Ha 是：本市的人均收入小于8000元。 我们对本市市民做了一次问卷调查，搜集了10000份问卷，根据数据调查结果，我们会有两种结论： 拒绝 H0，即接受 Ha 无法拒绝 H0 在上面的表述里，我们没有说“接受 H0”。这是外行最常用错的表达。 为啥不能说“接受”原假设在解答这个问题之前，我们需要先了解假设检验的方法论。 对每一个研究课题，我们的工作流程是： 确定 H0 和 Ha 根据过往的研究和理论，确定要使用的假设检验方法 选好一个显著性水平 significance level，比如 alhpa = 0.05 搜集数据，并计算 p 值 如果 p 值 &lt; alpha，我们说拒绝原假设，否则，我们说无法拒绝原假设 是否拒绝原假设，受到我们选择的 significance level 影响。如果 p 值等于 0.06，而我们的 significance level 选了0.05，因为0.06 &gt; 0.1，这个时候我们会“无法拒绝原假设”。而如果 significance level 选了0.1，因为0.06 &lt; 0.1，我们就能够拒绝原假设。 当我们做假设检验时，我们其实是在研究这个问题：给定原假设为真，我们有多大的可能观察到自己所搜集的数据，如果这个可能性很小，我们就拒绝原假设。当我们 p 值 &gt; alpha 时，本质上等价于：我们所搜集到的数据并没有极端到能说明原假设是错的。这里的极端程度标准，就是我们选好的 significance level。 以这个 H0 为例：本市的人均收入大于或等于8000元。 我们发现调查1万人的平均收入是7990元，这个数字比8000小，看上去人均收入似乎低于8000了，但要注意，抽样调查存在随机性，这10元的差距很有可能是随机现象导致。换句话说，我们观察到的数据不足以证明原假设是错的。 但我们是否能接受“人均收入大于或等于8000”的说法呢？显然不能，7990 的调查结果当然支撑不了这个说法。 如果我们想要证明人均收入大于8000，我们的原假设就应该是：人均收入小于或等于8000（原假设里一定要有等号）。 第1类错误和第2类错误理论部分搞清楚后，我们开始介绍第1类错误和第2类错误。 第1类错误：原假设为真，但我们拒绝了原假设。这类错误叫去真，英文文献里说 false positive。第2类错误：原假设为假，但我们没有拒绝原假设。这类错误叫存伪，英文文献里叫 false negative。 如下图： 犯第1类错误的概率，就是之前出现的 significance level。如果我们确定了 alpha = 0.05，那么在100次假设检验中，就会有5次出现第1类错误。 犯第2类错误的概率，被称为 beta，另一个常用统计学概念 power（统计功效）就等于 1 - beta。犯第2类错误的概率越低，建设检验的 power 就越高。 在这两类错误中，我们更关心哪一类呢？有的书籍会告诉我们第1类错误更重要，它们会用法庭审判的例子，说审判一个无罪的人有罪（第1类错误）是更大的风险，这其实只是个比喻，不是个好例子。下面我们看两个例子。 例子1我们用统计学使用的最严格的场景做例子：药物效果的判断。新药上市前，要经过一系列严格的医学试验。 H0：药物 A 对治疗某疾病没有帮助Ha：药物 A 对治疗某疾病有帮助 相关错误和结果如下： 第1类错误：药物 A 是没用的，但我们拒绝了原假设，给出了药物 A 是有用的的判断。药物上市，患者购买后没有帮助，患者因为使用 A 药物可能没有使用其他有效的药物，最后可能有负面结果（甚至死亡），进一步研究发现药物 A 是无效的，公司面料患者诉讼，甚至可能破产。 第2类错误：药物 A 是有用的，但我们没有拒绝原假设。结果：药物无法上市，公司损失了潜在的收入，病人失去了一种潜在的治疗方案。 两种结果，作为公司管理者的你，你会更希望减少哪一种错误的概率呢？显然是第1种。 例子2我们做疾病筛查时，H0 和 Ha 分别是： H0：病人没有疾病Ha：病人有疾病 相关错误如下： 第1类错误：病人是没病的，被诊断为有病。病人痛哭流涕，但在之后的进一步检查中，病人发现自己并没有生病，虚惊一场，进而联想到生命的可贵，于是变成一个好父亲好丈夫。 第2类错误：病人是有病的，但原假设没有被拒绝，病人不知道自己生病了，于是逍遥快活，错过了治疗时机，然后症状变严重时，才进一步检查，发现得了病。 在这个例子里，你会更希望减少哪一类错误的概率呢？显然是第2种。在 HIV 检测中，false negative 确实比 false positve 更少见。 实践在实际研究中，我们可以降低两类错误的概率： 第1类错误：通过选择更低的 significant level 第2类错误：通过扩大样本量或选择单侧检验 样本量足够大的时候，我们总是能把两类错误的概率降到足够低。但\b在实际应用中，更大的样本意味着成本：时间成本和金钱成本。 以 A/B 测试为例，只要样本量足够大，一定发现更好的方案。但产品有自己的迭代计划，每个产品有一系列的 A/B 测试需要做，不可能等每一个测试出现结果。这个时候就必须为了效率牺牲准确性。 有的领域，准确性非常非常重要，比如治疗癌症的药物研究，那是人命关天的事情，而且每天都在烧钱，真的是字面意义上的烧钱。 相比之下，互联网产品的容错率还是很高的。业界能够接受的标准一般是： 5%的犯一类错误的概率 20%的犯二类错误的概率 一般的产品按照这个标准去做研究，不会有大问题。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"统计理论","slug":"统计理论","permalink":"http://yoursite.com/categories/%E7%BB%9F%E8%AE%A1%E7%90%86%E8%AE%BA/"}],"tags":[]},{"title":"R 语言里常用的分布函数","slug":"r-dist-func","date":"2020-01-13T16:59:44.000Z","updated":"2020-01-22T19:42:39.787Z","comments":true,"path":"2020/01/13/r-dist-func/","link":"","permalink":"http://yoursite.com/2020/01/13/r-dist-func/","excerpt":"这篇博文小结 R 语言里涉及概率分布的几个函数。 每个概率分布函数在 R 里都有4个对应的函数，分别以1个字母开头： d：表示 density，指概率密度函数 probability density function (pdf) p：表示 probability，指累计分布函数 cumulative density function (cdf) q: 表示 quantile，是 cdf 的逆函数 r：表示 random，符合该概率分布的随机数 如果你像我一样已经不记得概率论的老师长啥样，上个的一些名词应该会让你一头雾水。没关系，我们接下来就用 R 代码一一测试。 \b","text":"这篇博文小结 R 语言里涉及概率分布的几个函数。 每个概率分布函数在 R 里都有4个对应的函数，分别以1个字母开头： d：表示 density，指概率密度函数 probability density function (pdf) p：表示 probability，指累计分布函数 cumulative density function (cdf) q: 表示 quantile，是 cdf 的逆函数 r：表示 random，符合该概率分布的随机数 如果你像我一样已经不记得概率论的老师长啥样，上个的一些名词应该会让你一头雾水。没关系，我们接下来就用 R 代码一一测试。 \b 二项分布 Binomial Distribution我们先以二项分布作为例子。二项分布是一个离散随机变量。 二项分布描述的问题是：每次试验有两个结果，成功或失败，n 次试验后成功 k 次的概率有多少？ R 语言里是 binom。 dbinomdbinom(x, size, prob) 就是计算概率的公式，其中： x：成功次数 size：总试验次数 prob：单次试验的成功概率 比如，扔5次硬币，正面2次的概率可以计算为： R代码1dbinom(2, size=5, prob=0.5) 结果：0.3125 pbinompbinom(q, size, prob) 是计算累计概率的函数，其中 q 是 quantile。 例子：扔5次硬币，最多有1次正面的概率是对少？(即0次或1次) R代码1pbinom(1, size=5, prob=0.5) 答案：0.1875。 我们可以用 dbinom(0, 5, 0.5) + dbinom(1, 5, 0.5) 来做验证 qbinomqbinom 是 pbinom 的逆函数。我可以计算累计概率为 p 的对应 quntile 是多少。 使用刚才的0.1875去计算： R代码1qbinom(0.1875, size=5, prob=0.5) 我们应该得到 1。 rbinomrbinom(n, size, prob) 给出 n 个符合二项分布的随机数。 我们刚才计算了扔5次硬币时，成功2次的概率是 0.3125。 现在我们分别生成100、1000和10000个随机数，看看 x = 2 的频率是不是接近这个数字。 R代码1234set.seed(123)sum(rbinom(100, 5, 0.5) == 2) / 100 # 0.28sum(rbinom(1000, 5, 0.5) == 2) / 1000 # 0.294sum(rbinom(10000, 5, 0.5) == 2) / 10000 # 0.3139 可以看到，随着随机次数的增加，成功2次的频率越来越接近理论值。 正态分布正态分布是一个连续随机变量。 dnormdnorm(x) 计算 x 的对应概率密度函数值。这个函数用处不大。因为连续随机变量在某一点的\b概率为 0。 这个函数的唯一用处，大概是方便大家画出概率密度函数图。 pnormpnorm(5) 实际上就是 P(X &lt;= 5)，计算了 X 小于等于5的概率。 所以，pnorm(0) 的结果是0.5，标准正态分布的一半嘛。 如果想计算期望等于1，标准差等于2的正太分布在 -3 &lt; x &lt;= 0 的概率呢？ R代码1pnorm(0, 1, 2) - pnorm(-3, 1, 2) 结果：0.2857874 qnormqnorm 是 pnorm 的逆函数。因为 pnorm(0)等于0.5，所以 qnorm(0.5)肯定等于0，不信你试试 :) 。 rnormrnorm 生成一组符合正态分布的随机数。 我们可以生成1000个数据，然后画图看看效果。 R代码12n1000 &lt;- rnorm(1000, mean = 70, sd = 5)hist(n1000, breaks = 20) 确实很符合正态分布。 rnorm 是个好伙伴，在 simulation study 时用得非常多。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Coding","slug":"Coding","permalink":"http://yoursite.com/categories/Coding/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"增长黑客系列之3：增长的三驾马车","slug":"2019-05-07-userGrow-3","date":"2019-05-06T17:15:47.000Z","updated":"2020-01-22T19:42:39.779Z","comments":true,"path":"2019/05/06/2019-05-07-userGrow-3/","link":"","permalink":"http://yoursite.com/2019/05/06/2019-05-07-userGrow-3/","excerpt":"我在本系列的前两篇文章里讨论了“裂变模型”，在裂变模型里，目标是“总用户数”。其实真正的增长目标，应该是日活跃用户数，也叫 DAU（Daily Active User）。 \b驱动产品的 DAU 的要素可以分为3个： 新增 留存/流失 裂变 成熟的增长团队，应该从上面3个维度着手来实现增长目标。 \b\b","text":"我在本系列的前两篇文章里讨论了“裂变模型”，在裂变模型里，目标是“总用户数”。其实真正的增长目标，应该是日活跃用户数，也叫 DAU（Daily Active User）。 \b驱动产品的 DAU 的要素可以分为3个： 新增 留存/流失 裂变 成熟的增长团队，应该从上面3个维度着手来实现增长目标。 \b\b 新增这里的新增一般指团队消耗精力或金钱获取到用户，也叫 UA （User Acquisition）。 最典型的 UA 行为是通过广告网络购买用户，这类广告因为可以衡量投入产出比，所以叫“效果广告”。比如我们在浏览朋友圈时看到的游戏广告，就是一个效果广告。 除此之外，品牌广告也是大公司常用的方法，比如抖音冠名赞助某个\b综艺节目。 增长黑客能够发挥作用的地方一般是在效果广告部分。 最典型的问题场景：公司每个月会花掉1000万的效果广告，如何最大化这1000万的效果呢？ 这个时候我们可以这样考虑问题： 是不是有投放效果比较差的渠道？如果有的话，我们应该在这些渠道减少投入。反之，有没有好的渠道可以增加投入。 广告的用户画像是否是当前最优解？有没有更便宜但效果更好的广告定位方案？ 广告的素材有没有可能优化？对应的指标是广告点击率。 广告的落地页有没有可能优化？对应的指标是落地页的转化率。 … 上面的每一个问题，有两种优化思路： 内部对比。比如对比 A 渠道和 B 渠道，对比 A 定位和 B 定位，然后相应修改投入方案。 外部 benchmark，即对比市面上产品的数据，这需要可靠的信息源。 留存/流失我们在提到留存时，经常指的是“次日留存”、“3人留存“等指标，这些指标描述了用户在第2天和第3天继续使用产品的比例。这只是一个方便衡量产品的指标，对优化产品的帮助并不十分大。 真正重要的概念，是流失 churn。 我们关心这些问题： 有多少比例的用户在1分钟内流失了？ 有多少比例的用户在进入产品的核心体验环节前就流失了？ 更抽象地，用户在各个产品环节的流失率情况怎样？ \b\b流失的用户有哪些共同特征？ 多少用户在第2天没再回来（通过这个数据也可以算出次日留存率） …… 一个好产品，最直观的表现是，用户会留下来。所以，较高的留存率、或较低的流失率，是优秀产品的共同特征。 产品的团队的最核心工作，就是解决留存问题，换个表述就是，解决“产品问题”。我甚至有一个观点：产品问题其实就是留存问题。 增长黑客可以在这个环节做什么呢？ 研究每个用户转化环节的流失情况，识别最严重的流失环节 设计 A/B 测试，对转化环节做优化 研究流失用户或留存用户的共性，用以知道产品优化 …… 裂变裂变，或病毒传播，是增长黑客的第3个工作重心。 裂变的价值我们在前两篇文章里已经介绍过，一个病毒因子足够高的产品，会给产品带来指数级别的增长。 增长黑客要做的事情，就是优化三个裂变相关的指标： 人均邀请数量：越高越好 感染率：越高越好 病毒传播的周期：越低越好 裂变有至少3种实现方式： 产品本身有天然的裂变属性：比如微信、Facebook、slack 这样有社交属性的产品 产品有某个裂变功能：如拼多多的“帮我砍价”，或知识付费产品的“分销” 通过运营活动实现裂变：比如瑞幸咖啡的“邀请用户，各得一杯” 根据不同的裂变实现方式，增长黑客会跟产品、运营等不同职能的同事合作。 更多阅读增长黑客系列： 基础裂变模型 升级版裂变模型 增长的三驾马车（本文） document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"增长黑客","slug":"增长黑客","permalink":"http://yoursite.com/categories/%E5%A2%9E%E9%95%BF%E9%BB%91%E5%AE%A2/"}],"tags":[]},{"title":"增长黑客系列之2：升级版裂变模型","slug":"2019-05-01-userGrow-2","date":"2019-05-01T09:39:14.000Z","updated":"2020-01-22T19:42:39.779Z","comments":true,"path":"2019/05/01/2019-05-01-userGrow-2/","link":"","permalink":"http://yoursite.com/2019/05/01/2019-05-01-userGrow-2/","excerpt":"本系列的上一篇文章 介绍了一个纯裂变模型。 我们在本篇加入一个新的变量：裂变周期的时长。直觉告诉我们，裂变周期越短，裂变强度越大。但是，这个强度究竟有多大呢？ 我让这个问题再精确一些，假设有2个产品，A 产品裂变周期只有1天，B 产品裂变周期是2天，30天后，A 产品的用户数会是 B 产品的几倍？ \b","text":"本系列的上一篇文章 介绍了一个纯裂变模型。 我们在本篇加入一个新的变量：裂变周期的时长。直觉告诉我们，裂变周期越短，裂变强度越大。但是，这个强度究竟有多大呢？ 我让这个问题再精确一些，假设有2个产品，A 产品裂变周期只有1天，B 产品裂变周期是2天，30天后，A 产品的用户数会是 B 产品的几倍？ \b 丧尸的世界为什么那么刺激在去看枯燥的公式和代码之前，我先谈谈有趣的丧尸。丧尸题材在现代社会的风靡是个有意思的现象，我把这个想象叫做“双重逃避”。 第一重逃避是现代人对充满压力的生活的逃避：通过丧尸电影和丧尸游戏，人们沉浸到了一个紧张刺激的世界，让我们忘掉日常生活的种种压力。第二重逃避：我们在丧尸游戏和电影里逃避着无处不在的丧尸。所以，为了逃避现实，我们选择在虚拟的世界里逃避丧尸。 为什么逃避丧尸是个那么刺激的事情呢？一种解答是：丧尸很致命。但这个答案不够完美，因为致命的东西很多，比如哥斯拉和异形就比丧尸致命得多。如果致命程度是某个题材火爆的原因，我们应该看到哥斯拉和异形更流行。 我觉得真正的原因是：丧尸有非常强的病毒传播能力。从第1只丧尸诞生到丧尸围城，用不了几天时间（额外提问：这现实吗？）。 我们在上一篇系列文章里提到了两个核心变量： 邀请数量 感染率 \b在丧尸的世界里， 丧尸是非常热情的“种子用户”，它见到人就会发出“邀请”，而且感染率100%。所以丧尸有非常高的病毒因子。 但这个指标还不足以描述丧尸的可怕（或魅力）。丧尸电影里最刺激的情节是，男主角的朋友/爱人被咬了之后，1分钟内就会变成丧尸，然后会立刻开始进攻其他人类。换句话说，僵尸把人变成僵尸的周期非常快。在增长模型里，这个参数叫做“周期时长”。僵尸有非常短的周期时长。 如果被僵尸咬了之后需要48个小时才会变异，僵尸电影就没那么有意思了。 新的模型在新的模型里，我们开始考虑一个周期的时间长度，这个变量叫做简称为 ct。 所有变量如下： 初始用户：custs(0) 周期时长：ct 人均邀请数 i 感染率 Conv% 我们想要计算的指标是：\b第 t 天时，总的用户数是多少，这个变量是 custs(t)。 我们仍然维持上一篇文章的核心假设：只有新用户会发出邀请。 我从风险投资人 David Skok 的博客里找到了计算第 t 天总用户量的公式： 公式里的 K = conv% * i 根据上面的公式，我们的 R 代码如下： 12345get_cust_t &lt;- function(cust_0, i, conv, ct, t) { k_coef &lt;- i * conv cust_t &lt;- cust_0 * ( k_coef ^ (t/ct + 1) - 1) / ( k_coef - 1) return(cust_t)} 数据例子当 ct = 1 时，一天就能完成一次裂变。我们想研究的问题是，当裂变时长分别等于 1、2、3、4 时，30天后的总用户数会有什么样的差距。 结果如下图： 第0天 第1天 第10天 第20天 第30天 ct = 1 10 25 1710 99738 5752512 ct = 2 10 17 208 1710 13117 ct = 3 10 14 96 428 1710 ct = 4 10 13 63 208 608 天壤之别。 如果数字还不够直观的话，我们就看看图片。 我先画出了 ct = 2、3、4 时的图片： 看上去 ct = 2 时的效果是远远强于 ct = 3 和 ct = 4 的。 如果对比 ct = 1 和 ct = 2 呢？ 真正意义上的天壤之别。在 ct = 1 的产品面前，排名老二的产品跟不存在一样。 我们在最开始提了一个问题：假设有2个产品，A 产品裂变周期只有1天，B 产品裂变周期是2天，30天后，A 产品的用户数会是 B 产品的几倍？答案：438倍！ 这张图给了我两个想法： 天下武功，唯快不破。在有病毒裂变能力的领域尤其如此。 \b有的时候你以为自己比后面的对手要厉害一截，但在第一名看来，你们都是一样渺小。 这个模型的实践意义上一个模型告诉我们要提高用户邀请数， 要提高邀请成功率。 这个模型告诉我们：要缩短病毒传播的周期时长。这个话题会在接下来的系列中讨论。 结束这篇文章前，我们再想想下丧尸题材的常见现象：从第1只僵尸诞生到丧尸围城，只需要几天时间。现在你还会怀疑这个设定是否现实吗？ 更多阅读增长黑客系列： 基础裂变模型 升级版裂变模型（本文） 增长的3架马车 参考： David Skok: Lessons Learned – Viral Marketing document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"增长黑客","slug":"增长黑客","permalink":"http://yoursite.com/categories/%E5%A2%9E%E9%95%BF%E9%BB%91%E5%AE%A2/"}],"tags":[]},{"title":"ggplot系列之：boxplot","slug":"2019-04-15-ggplot系列3","date":"2019-04-15T01:07:33.000Z","updated":"2020-01-22T19:42:39.779Z","comments":true,"path":"2019/04/15/2019-04-15-ggplot系列3/","link":"","permalink":"http://yoursite.com/2019/04/15/2019-04-15-ggplot%E7%B3%BB%E5%88%973/","excerpt":"数据可视化的常见场景之一是：展示一个 categorical variable 和一个 numeric variable 的关系。 这时我们可以使用 boxplot。 这里使用了 FIFA 的球员数据集。","text":"数据可视化的常见场景之一是：展示一个 categorical variable 和一个 numeric variable 的关系。 这时我们可以使用 boxplot。 这里使用了 FIFA 的球员数据集。 大球队的工资状况如何？我们想展示几个大球队的工资状况，涉及两个变量： 球队：categorical variable 每个球员的工资：numerical variable 我们先提取几个大俱乐部的数据，并把周薪修改为万欧： 12345678910111213141516# 需要的俱乐部clubs &lt;- c('Real Madrid', 'FC Barcelona', 'Manchester United', 'Manchester City', 'Liverpool', 'Chelsea', 'Arsenal', 'Borussia Dortmund', 'FC Bayern München')wage_to_number &lt;- function(wage) { # 把周薪转换成万欧 number_in_string &lt;- str_extract(wage, '\\\\d+') number_in_1000 &lt;- as.numeric(number_in_string) number_in_1000 * 1000 / 10000}sub_dat &lt;- dat %&gt;% filter(Club %in% clubs) %&gt;% mutate(Wage = wage_to_number(Wage)) 下面制作 boxplot： 123456ggplot(sub_dat) + geom_boxplot(aes(x = Club, y = Wage)) + labs(x = NULL, y = '工资（周薪：万欧）', title = '各大俱乐部的工资结构') + coord_flip() 结果如图： 从这个图可以看到： 西超双雄、曼城和尤文图斯的工资中位数最高 多特蒙德的工资水平最低，确实是这几个队里经济实力最低的 利物浦、切尔西、阿森纳、拜仁在维持相对均衡的收入的同时，还允许超级巨星有高收入 巴塞罗那有一个收入最高的家伙，不用想，当然是梅西啦 我们想标注出几个离群值有几个球队有收入远远高于队友的球员，我们想看看他们究竟是谁（虽然猜也能猜到了 😊)，并把他们的名字标注在图片上。 先清理数据： 12345outliner_club &lt;- c('FC Barcelona', 'Liverpool', 'Chelsea', 'Arsenal', 'FC Bayern München')outliner_player &lt;- sub_dat %&gt;% filter(Club %in% outliner_club) %&gt;% group_by(Club) %&gt;% filter(Wage == max(Wage)) 我们提取出了几个有离群值的俱乐部收入最高的球员。 然后，我们在图片上添加 label： 1234567891011ggplot(sub_dat, aes(x = Club, y = Wage)) + geom_boxplot() + geom_label(data = outliner_player, aes(label = Name), nudge_x = 0.25, nudge_y = 0.25, label.size = 0.1) + labs(x = NULL, y = '工资（周薪：万欧）', title = '各大俱乐部的工资结构') + coord_flip() 结果如下： 各个全队的异常高收入球员如下： 巴萨：梅西 切尔西：C罗 拜仁：J罗 利物浦：萨拉赫 切尔西：阿扎尔 阿森纳：奥巴梅杨 有意思的是，利物浦的最高薪球员萨拉赫，薪资水平在皇马也只属于前1/4，在巴萨甚至不到梅西的一半。可见西超双雄的购买力了。 给曼联上色作为一个曼联球迷，我想给曼联的 box 涂上曼联红色，然后给死敌利物浦涂上他们死敌埃弗顿的蓝色 😃，我该怎么办呢？ 12345678910111213141516sub_dat &lt;- sub_dat %&gt;% mutate(isManU = case_when( Club == 'Manchester United' ~ 'ManU', Club == 'Liverpool' ~ 'Liv', TRUE ~ 'rest' ))ggplot(sub_dat) + geom_boxplot(aes(x = Club, y = Wage, fill=isManU)) + scale_fill_manual(breaks = c(\"Liv\", \"ManU\", \"rest\"), values=c(\"#003399\", \"#DA291C\", \"white\")) + labs(x = NULL, y = '工资（周薪：万欧）', title = '各大俱乐部的工资结构') + coord_flip() + theme(legend.position = \"none\") 结果如下图： 希望利物浦球迷看到了不要打我 💣 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据可视化","slug":"数据可视化","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"数据科学：用 R 还是 Python?","slug":"2019-04-05-RorPython","date":"2019-04-05T08:05:05.000Z","updated":"2020-01-22T19:42:39.779Z","comments":true,"path":"2019/04/05/2019-04-05-RorPython/","link":"","permalink":"http://yoursite.com/2019/04/05/2019-04-05-RorPython/","excerpt":"网上经常看到人讨论：R 和 Python，哪个更好呢？ 我不太喜欢这个问题，因为“好”的标准实在太多，不同场景有不同的标准。初学者为了快速了解统计学，最合适的肯定是 R；做人工智能的团队为了使用 Tensorflow 等开源工具，最适合的肯定是 python。 所以在讨论这个话题之前，我先限定好场景：一个大公司内需要进行庞大业务分析的数据团队。在这个场景内，应该使用哪个工具呢？ 我的方案是：R 和 python 都使用，但两者有不同的使用场合。","text":"网上经常看到人讨论：R 和 Python，哪个更好呢？ 我不太喜欢这个问题，因为“好”的标准实在太多，不同场景有不同的标准。初学者为了快速了解统计学，最合适的肯定是 R；做人工智能的团队为了使用 Tensorflow 等开源工具，最适合的肯定是 python。 所以在讨论这个话题之前，我先限定好场景：一个大公司内需要进行庞大业务分析的数据团队。在这个场景内，应该使用哪个工具呢？ 我的方案是：R 和 python 都使用，但两者有不同的使用场合。 PythonPython 明显强过 R 的地方有三点： Python 是通用语言，能解决数据分析之外的各种问题 对机器学习和人工智能的支持 Python 是更“优雅”的语言 Python 是通用型语言，可以用来解决各种问题。因为用 python 解决不同问题的人很多，所以程序员们基于 python 开发了大量的工具。想做 http 访问，可以使用 requests 包。想写爬虫，有 scrapy 包。想连接 SQL 数据库，有 SQLAlchemy 包…..大部分问题都能在 python 上找到对应的工具。而且，这些工具大概率比 R 语言的 library 要强大。毕竟，给 R 语言写工具的，一般是统计学家，给 python 写工具的，一般是 coder，后者的工具开发能力、文档的可读性都强于前者。 再说机器学习和人工智能，python 是这个领域的默认语言，tensorflow、pytorch 等开源方案都优先支持 python。 Python 创建之初，就是在设计一个“简单易用”的语言（这里的“简单易用”要打一个双引号，因为牺牲了其他的东西，但这对数据分析影响不大）。写 python 代码是一种享受。阅读写得好的 python 代码也是一种享受。 RR 比 python 强大的地方也有： R是专门为统计学设计的语言 强大的统计生态 强大的数据相关辅助工具 \bR 是专门为统计学设计的语言，python 是更底层的语言，所以做统计分析时，python 需要使用 pandas 等 package，而 R 可以快速上手，直接开始分析。想要使用 python 做数据分析，其实需要学习两个东西：python 和 pandas。Pandas 是开发者参考 R 语言开发的。 Python 有强大的整体生态，R 则有强大的统计生态。至少在我写这篇文章时，统计学届的默认分析语言基本是 R 语言。\b世界上最新的统计方法，都能在 R 语言中找到。 另外，R 语言的数据清洗工具、数据可视化工具和数据报告工具都强过 python。 数据清洗：Hadly Wickham 大神的 tidyverse 系列简直是人类智慧的结晶，这套工具集把数据清洗变成了一种享受。 数据可视化：还是 Hadly Wickham 大神，他的 ggplot 工具，\b帮助我们重新重构了数据可视化的思考模式。 数据报告工具：这要感谢中国的 Yihui 大神，他的 knitr、rmarkdown 等工具，让数据报告的产出变得更轻松、简单且科学规范。 1 + 1 &gt; 2\b\b说完了两者的优点，现在来说说如何结合两者。 我使用 python 的场合： 与数据库的沟通，因为 python 连接数据库的工具非常好用 Restful API 访问，使用 requests 包 \b非结构化数据的获取和清洗 机器学习 我使用 R 的场合： 规范性数据的清洗 统计学假设检验 数据可视化和数据报告 上面的使用场景应该是最能发挥两者优势的。不过按照 python 生态的发展速度，也许很快 python 就会在统计学、可视化和报告产出上超过 R 语言。如果到了那一天，也许只使用 python 就够了。 如果必须二选一呢？ 小孩子才做选择题，成年人全都要。 当然，学习 python 和 R 都挺容易的，如果只是做数据分析的话，会 python 的人可以在两周内掌握 R，反之也成立。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据科学","slug":"数据科学","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"},{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"}]},{"title":"增长黑客系列之1：基础裂变模型","slug":"2019-03-05-userGrow-1","date":"2019-03-05T13:15:49.000Z","updated":"2020-01-22T19:42:39.779Z","comments":true,"path":"2019/03/05/2019-03-05-userGrow-1/","link":"","permalink":"http://yoursite.com/2019/03/05/2019-03-05-userGrow-1/","excerpt":"增长黑客是近几年非常火爆的概念，指利用各种技术手段和产品手段帮助产品实现快速增长的人。其实在这个概念出现之前，增长就已经是一个技术和产品的混合领域了。 按照增长黑客的理念，用户增长的起点不是从市场营销阶段开始，而是从产品的设计阶段就做了规划。比如，当今的所有产品都会考虑用户的自发推广。 这个系列文章会建立一套增长黑客的数学模型，帮助我们更好地理解增长。 我们先从最简单的世界开始。 在这个“创世篇”里，所有产品都只能在发布时做一次市场营销，之后的新用户都必须来自老用户的推荐。 这个世界的增长故事会长成什么样呢？ \b","text":"增长黑客是近几年非常火爆的概念，指利用各种技术手段和产品手段帮助产品实现快速增长的人。其实在这个概念出现之前，增长就已经是一个技术和产品的混合领域了。 按照增长黑客的理念，用户增长的起点不是从市场营销阶段开始，而是从产品的设计阶段就做了规划。比如，当今的所有产品都会考虑用户的自发推广。 这个系列文章会建立一套增长黑客的数学模型，帮助我们更好地理解增长。 我们先从最简单的世界开始。 在这个“创世篇”里，所有产品都只能在发布时做一次市场营销，之后的新用户都必须来自老用户的推荐。 这个世界的增长故事会长成什么样呢？ \b 建立模型我们的模型有几个变量： 第0期的用户数 C_0：最开始的用户数 人均邀请数 i：每个新用户发出去的邀请人数 感染率 Conv%：一个百分数，指每次邀请的成功率 这里有个重要假设：每个周期只有新用户会发出邀请。相比于所有用户会在每个周期都发出邀请，这是个更合理的假设。 场景：每一个周期，每个新用户会邀请 i 个用户，这些用户有 Conv% 的概率会成功变成我们的用户。问题：到了第 t 期，我们的总用户会有多少个呢？ 进一步计算前，我们就需要提到一个著名的概念病毒因子，病毒因子的公式是：人均邀请数 * 感染率%。 比如，如果人均邀请数是 10，感染率是 20%，那么第 t 期的每个新用户在第 t + 1 期会给我们带来 2 个新用户，这时病毒因子是 2。 理解了这个定义后，我们就能定义一个数学模型了。 第 t 期的新用户数 = 第 t - 1 期的新用户数 * 病毒系数 第 t 期的总用户数 = 第 t - 1 期的总用户数 + 第 t 期的新用户数 R 代码我们可以用 R 写一套函数，根据不同参数计算总的裂变结果： 1234567891011121314151617181920get_new_customer &lt;- function(new_customer_last, i, conv) { viral_coef &lt;- i * conv return(new_customer_last * viral_coef)}get_cycle_data &lt;- function(customer_0, i, conv, t) { df &lt;- data.frame(matrix(ncol = 3, nrow = t)) colnames(df) &lt;- c('cycle', 'new_user', 'total_user') customer_total &lt;- customer_0 new_customer_last &lt;- customer_0 for ( t_i in 1:t) { customer_new &lt;- get_new_customer(new_customer_last, i, conv) customer_total &lt;- customer_total + customer_new new_customer_last &lt;- customer_new df[t_i, ] &lt;- list(t_i, customer_new, customer_total) } return(df)} 我在这里写了两个函数。 第一个函数会根据上一期的用户数、人均邀请数、感染率计算当期新用户 第二个函数会完整返回整个周期的新用户数、总用户数 病毒系数 = 1 时我们先用第一组参数测试： t = 0 时，新用户有10个人 人均邀请数 = 10 感染率 = 10% 此时病毒系数为 1，经过12个周期后，用户数据长什么样呢？ 周期 新用户 总用户 1 10 20 2 10 30 3 10 40 4 10 50 5 10 60 6 10 70 7 10 80 8 10 90 9 10 100 10 10 110 11 10 120 12 10 130 可以看到，每个周期的新用户数只有10个，12个周期后，用户只有130个。 从数学上来说，病毒系数等于1意味着： 用户会有自然增长 用户每期的增长速度平缓，是线性的 从产品上来所，这不是个令人兴奋的场景 病毒系数 = 0.5 时上一个产品的数据太差，我们换了个新产品。但因为产品设计问题，这个产品的用户没有那么强的分享欲望，人均分享减半了。 参数如下： t = 0 时，新用户有10个人 人均邀请数 = 5 感染率 = 10% 结果如下（因为是数学模型，所以不用在乎0.5个人的问题）： 周期 新用户 总用户 1 5.00 15.00 2 2.50 17.50 3 1.25 18.75 4 0.62 19.38 5 0.31 19.69 6 0.16 19.84 7 0.08 19.92 8 0.04 19.96 9 0.02 19.98 10 0.01 19.99 11 0.00 20.00 12 0.00 20.00 在病毒系数等于0.5时，产品的用户数很快会停止增长，理论上的最大值是20个人，仅仅是初期用户数的两倍。谁都不希望开发这样的产品。 病毒系数 = 2 时上一个产品的数据让老板无法忍受，也是我们开发了一个新产品。我们优化了邀请的截图和文案，让邀请的感染率上升到了15%。 参数如下： t = 0 时，新用户有10个人 人均邀请数 = 10 感染率 = 20% 周期 新用户 总用户 1 20 30 2 40 70 3 80 150 4 160 310 5 320 630 6 640 1270 7 1280 2550 8 2560 5110 9 5120 10230 10 10240 20470 11 20480 40950 12 40960 81910 病毒系数等于2时，\b12个周期后，产品的总用户数会达到8.1万。最神奇的是，用户数在某个周期几乎是翻倍增长。如果你碰到这样的产品，恭喜你，你离财富自由已经不远了。 用图片病毒系数的差距的影响病毒系数不大于1，理论上我们实现不了自然增长和裂变。我们直到病毒系数越大越好，可是当病毒系数的大于1时，每增加0.2，究竟会有多大影响呢？ 我们把这个数据用图片表示出来。 虽然只是0.2的差异，但12个周期之后，不同病毒系数的表现是天壤之别。如果你对指数增长有所了解，应该会发现病毒系数较高时，用户增长是指数形式的。在指数模型下，每1个点的增长，都会是长期来看巨大的增长。 模型的实践意义这个简单的模型告诉我们： 病毒系数是裂变模型里最重要的因素 要统计产品的人均邀请数和的感染率 不断优化人均邀请数和感染率 不要小看这个实践意义，很多产品是完全没有统计邀请用户邀请数和邀请成功率的，如果连基本的“测量”都不做，又怎么谈得上基于数据的优化呢？ If you can’t measure it, you can’t improve it. 更多阅读增长黑客系列文章： 基础裂变模型 升级版裂变模型 增长的3架马车 参考： David Skok: Lessons Learned – Viral Marketing document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"增长黑客","slug":"增长黑客","permalink":"http://yoursite.com/categories/%E5%A2%9E%E9%95%BF%E9%BB%91%E5%AE%A2/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"JavaScript：如何理解“异步”和“同步”","slug":"2018-07-01-Async","date":"2018-07-01T10:55:04.000Z","updated":"2020-01-22T19:42:39.775Z","comments":true,"path":"2018/07/01/2018-07-01-Async/","link":"","permalink":"http://yoursite.com/2018/07/01/2018-07-01-Async/","excerpt":"怎么理解 async（异步） 和 sync（同步） 呢？","text":"怎么理解 async（异步） 和 sync（同步） 呢？ 一个比喻解释： sync：指代码按照顺序执行，一段代码执行完后，再去执行下一段。 async：一行代码发出调用指令后，不去等待这段代码的执行结果，就直接去执行下一段代码。 上面的解释可能比较抽象，我们做一个比喻：想象你在星巴克排队买咖啡。 sync：轮到你点咖啡，你选好了咖啡，告诉咖啡师，咖啡师开始做咖啡，你在柜台前等待，不能做任何别的事情，静静地等咖啡师把咖啡做完。拿到咖啡后，你才能去做下一件事情，比如找到座位开始工作。 async：\b轮到你点咖啡，你选好了咖啡，告诉咖啡师，然后你找了个座位，打开电脑开始工作，咖啡师做好咖啡后，把咖啡拿给你。 Sync 的顺序如下图： 在 sync 模式下，拿到咖啡之前，我们什么也干不了，只能干等着。 Async 的顺序如下图： 在 async 模式下，咖啡师在煮咖啡，我们可以先去忙别的事情，当咖啡师做完咖啡后，我们会收到咖啡。这种模式更节约时间。 JavaScript 的例子我们把上面的例子用 JavaScript 代码来执行： Sync12345678910111213console.log(\"点咖啡\")console.log(\"------等待2分钟-----\")console.log(\"拿到咖啡\")console.log(\"找座位\")console.log(\"打开电脑\")console.log(\"开始工作\")//点咖啡//------等待2分钟-----//拿到咖啡//找座位//打开电脑//开始工作 可以看到，一切都按照顺序进行。 然后是 Async 的代码Async123456789101112131415console.log(\"点咖啡\")setTimeout(() =&gt; { console.log(\"-----2分钟过去了-----\") console.log(\"拿到咖啡\")}, 2)console.log(\"找座位\")console.log(\"打开电脑\")console.log(\"开始工作\")//点咖啡//找座位//打开电脑//开始工作//-----2分钟过去了-----//拿到咖啡 这里有意思的地方是， “——-2分钟过去了——-” 和 “拿到咖啡” 在顺序上是第2和第3位，但因为异步，它们在最后才被执行。我们利用空闲的时间先处理了之后的工作。 什么场合使用 async 和 sync咖啡师做咖啡是一件消耗时间的任务，在 app 开发时也有类似的任务，比如客户端从数据库获取数据，我们不知道要等待多久，这时候就可以使用 async，让我们的客户端在获取到数据前先做其他工作。 使用 async 的典型场景： 访问 API 数据库的读写 \b调用某个第三方 JavaScript 包 …… 使用 sync 的典型场景：程序操作之间有明显的顺序关系。如用户输入账号密码、校验、登陆，这是一个明显有顺序的流程。 另一个思考方式是：当你不知道该用 async 还是 sync 时，就先默认用 sync 吧。 参考： Is JavaScript Synchronous or Asynchronous? What the Hell is a Promise? JavaScript: Execution of Synchronous and Asynchronous codes FASTapi - Concurrency and async / await Understanding Async Await document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Coding","slug":"Coding","permalink":"http://yoursite.com/categories/Coding/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"http://yoursite.com/tags/JavaScript/"}]},{"title":"数据团队的三个角色：数据科学家、数据分析师、数据工程师","slug":"2018-05-07-数据团队","date":"2018-05-06T18:39:41.000Z","updated":"2020-01-22T19:42:39.775Z","comments":true,"path":"2018/05/06/2018-05-07-数据团队/","link":"","permalink":"http://yoursite.com/2018/05/06/2018-05-07-%E6%95%B0%E6%8D%AE%E5%9B%A2%E9%98%9F/","excerpt":"一般来说，一个完整的数据团队应该由3个角色构成： 数据分析师 data analyst 数据工程师 data engineer 数据科学家 data scientist 这篇文章总结三个角色的区别，并说明何种情况下团队里应该有这些角色。","text":"一般来说，一个完整的数据团队应该由3个角色构成： 数据分析师 data analyst 数据工程师 data engineer 数据科学家 data scientist 这篇文章总结三个角色的区别，并说明何种情况下团队里应该有这些角色。 三个角色三个角色的工作有时会有一定程度的交集，这里只讨论三个角色的最重要差异。 数据分析师： 需要了解业务，使用常规的数据分析方法为日常商业决策提供依据 数据工程师：创造和维护数据基础设施 数据科学家：掌握机器学习算法，擅长数学、统计学和编程，可以处理大数据分析需求 数据分析师数据分析师是最常见的角色，已经存在了很多年。早期的数据分析师只需要掌握 Excel 的使用，生成日常数据报表，做一定的数据可视化。一般情况下，数据分析师还需要懂业务，并通过数据对商业决策提供建议。 稍微进阶的数据分析师，还会懂一些 inferential statistics，使用线性回归等方法做归因和预测。 随着大家的学习能力越来越强，数据分析已经变成了一个基本技能。在这个环境下，数据分析师的核心价值是什么呢？我认为是“懂业务”。 数据分析师需要非常了解自己业务的情况，拿游戏来举例，数据分析师应该了解自己所分析的游戏、了解游戏行业的数据特点。SLG 游戏和 ARPG 游戏就是两个完全不同的游戏类型，如果某个核心指标相同（比如7日ROI），数据分析师需要针对两种游戏做不同的判断。同时，数据分析师应该深度体验自己的游戏，并能结合游戏体验提出值得研究的问题。 因为“懂业务”同时也“懂数据”，数据分析师应该是最能影响项目决策的人。 数据分析师的常见学科背景：商科、经济学、统计学。 数据工程师数据工程师其实是“需要做数据相关开发工作”的程序员，比如数据存储、数据计算、\b\b数据后台的搭建等等。 在小一些的公司，数据工程师一般由后端开发人员兼任。大型的公司，会需要专门的数据工程师。 数据工程师的常见学科背景：计算机。 数据科学家数据科学家是最近几年又硅谷带动起来的新兴岗位。数据科学家最核心的特点是：能用科学的方法解决企业的数据分析问题。 为什么这里提到“科学的”方法呢？有两个原因。 第1，很多数据分析师的分析工作其实充满了主观判断，毫无科学性可言。举个例子，我在某上市游戏公司的数据部门上班时，发现他们的数据分析报告从来不会使用假设检验，重要决策只通过画图寻找相关性后“主观判断”。数据分析其实是个有着严格科学基础的工作，专业的数据科学家会让团队的数据决策更加准确。 第2，大数据的兴起，让数据分析工作从传统的 excel 就能解决变成必须依赖高强度的编程能力和数学能力。 数据科学家有如下特点： 高学历 强大的数学和统计学能力 了解机器学习、NLP 等新兴\b数据分析领域的情况 强大的（数学）编程水平 相比于数据分析师，数据科学家可能不是那么懂业务。相比于数据工程师，数据科学家又不是那么懂数据库、API。 \b 三个角色的需求数据分析师：大中小型团队都需要的角色数据工程师：大型团队需要数据科学家：大型团队需要 我了解的美国某著名游戏公司的情况： 每一个项目里都有数据分析师，专门负责这个项目的分析工作和决策支持 数据工程师和数据科学家，不跟随项目走，在项目需要的时候提供工程支持和理论支持 工作场景举例： 数据分析师：日常分析需求、数据分析报告 数据工程师：分析师想要增加10个埋点，工程师满足这个需求 数据科学家：审查数据分析师的分析报告是否符合科学规范 对最顶级的公司，竞争的核心点其实是数据科学家。一个强大的数据科学家团队，可以让数据决策的精准度得到巨大提高。因为，数据科学家可以把结论用概率的形式科学的表示出来。（也许某些数据分析师也可以，但我不敢信他们啊）。 如果没有数据科学家，很有可能出现两种情况： 数据分析师给出质量无法保证的数据分析结果 团队依靠“数据可视化”的图像做出“猜测” 什么叫“团队依靠图像做出猜测”呢？举个让我印象深刻的例子吧。在游戏公司上班时，项目负责人拉数据之后画两个折线图，发现两者都有向上的趋势，于是推测出两者正相关，进而得出了一个行动依据。在懂数据分析的人看来，这大概跟“夜观天象”的靠谱程度差不多吧。一个数据科学家会在这个问题上给出严谨的数学公式、编程计算和结果报告，这就是数据科学家的价值。 但是，只有在尊重科学的公司，数据科学家的声音才会被重视。这可能也是硅谷才有这么多数据科学家岗位的原因吧啊。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据科学","slug":"数据科学","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"}],"tags":[]},{"title":"常用离散概率分布模型","slug":"2017-09-13-distributions","date":"2017-09-13T11:36:12.000Z","updated":"2020-01-22T19:42:39.775Z","comments":true,"path":"2017/09/13/2017-09-13-distributions/","link":"","permalink":"http://yoursite.com/2017/09/13/2017-09-13-distributions/","excerpt":"最近帮游戏开发的朋友做简单的建模，算数值模型的概率，发现自己把常用离散分布忘得差不多了。在这里简单复习一下。 \b以前在学校学习时，会有人去记忆概率分布的函数，其实分布的公式、期望、方差都是随便就能从网络上找到的，完全不需要记忆，\b真正需要记忆的是：知道该在什么场合去使用某个分布。 \b","text":"最近帮游戏开发的朋友做简单的建模，算数值模型的概率，发现自己把常用离散分布忘得差不多了。在这里简单复习一下。 \b以前在学校学习时，会有人去记忆概率分布的函数，其实分布的公式、期望、方差都是随便就能从网络上找到的，完全不需要记忆，\b真正需要记忆的是：知道该在什么场合去使用某个分布。 \b 伯努利分布符合伯努利分布 bernoulli distribution 的随机试验只有两种结果：1 或 0。最典型的伯努利分布是抛硬币，结果要么正面要么反面。 设抛到正面的概率是 p，抛到正面时的结果是 1，那么 p 就是伯努利分布的期望。 伯努利分布是一个基础分布，之后的几个分布都基于伯努利试验推导出。 几何分布几何分布 geometric distribution 用来描述这个问题：设计一系列试验，试验只有两种结果，需要多少次试验才能观察到一个成功的试验。 几何分布的例子：假设某男生追求女生的概率是10%，男生追求第5个女生时才获得成功的概率是多少呢？ 公式：p(5） = 0.9 ^ 4 * 0.1 = 6.6% 二项分布二项分布 binomial distribution 应该是最实用的分布之一，它描述的问题是：每次试验有两个结果，成功或失败，n 次试验后成功 k 次的概率有多少？ 我们继续用之前的场景：男生追求女生5次，成功1次的概率有多少？ R代码1dbinom(1, size=5, prob=0.1) 答案：32.8%。还是蛮高的。 当然，如果我们把问题修改为“至少成功1次的概率有多少？”，公式变为： R代码11 - dbinom(0, size=5, prob=0.1) 结果：41%。 如果把次数增加到15次呢？ R代码11 - dbinom(0, size=15, prob=0.1) 结果：79.4%。 假设这个男生每个月追求一个新目标，在20个月内脱单的概率是79%，虽然这个男生每次只有10%的成功率。 如果这位男生再努力一些，认真工作、好好锻炼、培养几个有趣的兴趣爱好，把自己每次成功的概率提高到20%，整体成功率会有多大的变化呢？ R代码11 - dbinom(0, size=15, prob=0.1) 结果：96.4% 这说明了一个道理：在婚恋市场上，没有天生的失败者，只有懒人。概率论对每个单身青年（或任何想在其他事情上获得成功的人）的建议是： 增加尝试次数 增加基础成功率 当然，这个例子还有一个隐藏的假设：活下去，让自己有能够持续尝试的能力。 对于投资者，这意味着不要 all in。 聪明的你应该看出来了，“至少成功一次”的计算不需要用到二项分布，用简单的概率论就能计算。如果你想当个花花公子，“至少成功不止一次”，二项分布会是你的动力来源。 负二项分布负二项分布 negative binomial distribution 描述的是：在第 x 次失败后获得第 k 次成功的概率。 一个新例子，篮球运动员小明被教练要求做罚球训练，罚进3个球后就能回家。小明的罚球命中率是30%，请问小明在第3-8次罚球时刚好完成任务的概率有多高呢？这个问题可以翻译成：小明在失败0-5次后完成任务的概率有多高。 R代码1dnbinom(0:5, 3, 0.5) 结果： 罚球次数 任务完成概率 3 12.5% 4 18.75% 5 18.75% 6 15.6% 7 11.7% 8 8.2% 小明最有可能在第4到第5次完成任务，懂行的人就可以在这里开个盘口，让大家下注啦。 泊松分布当我们知道某个相互独立事件在一段时间内的发生频率时，泊松分布 poisson distribution 可以用来描述这段时间内该事件发生次数的概率分布。 例子：已知平均每分钟有12量车经过一座桥，请问一分钟内有至少17量车经过这座桥的概率是多少？ R代码1ppois(16, lambda=12, lower=FALSE) 答案：10.1% document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"统计理论","slug":"统计理论","permalink":"http://yoursite.com/categories/%E7%BB%9F%E8%AE%A1%E7%90%86%E8%AE%BA/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"ggplot系列之三：查看一组连续变量的分布","slug":"2017-04-25-ggplot查看分布","date":"2017-04-25T09:40:26.000Z","updated":"2020-01-22T19:42:39.775Z","comments":true,"path":"2017/04/25/2017-04-25-ggplot查看分布/","link":"","permalink":"http://yoursite.com/2017/04/25/2017-04-25-ggplot%E6%9F%A5%E7%9C%8B%E5%88%86%E5%B8%83/","excerpt":"我们拿到了一个调查数据，每个用户输入了自己的年龄，我们想查看用户的年龄分布。这个问题场景其实可以抽象为：查看一个连续变量的分布情况。这时，我们可以使用直方图（histogram plot）或密度图（density plot）。 这篇文章展示两种图片的代码，并讨论该选择哪一种图片。","text":"我们拿到了一个调查数据，每个用户输入了自己的年龄，我们想查看用户的年龄分布。这个问题场景其实可以抽象为：查看一个连续变量的分布情况。这时，我们可以使用直方图（histogram plot）或密度图（density plot）。 这篇文章展示两种图片的代码，并讨论该选择哪一种图片。 模拟数据我们先生成 simulated data： 变量1：性别，男或女 变量2：重量，符合正太分布 \b数量：男女各两百各观测值 12345set.seed(1234)wdata &lt;- data.frame( sex = factor(rep(c(\"女\", \"男\"), each=200)), weight = c(rnorm(200, 55), rnorm(200, 58)))head(wdata) histogramhistogram 把一组连续变量分成若干组，并展示各个组的频数。ggplot 可以对连续变量自动分组，我们也可以手动设定每一组的区间范围。具体使用多大的组距，要根据业务情况确定。 我们先做第一张图，不区分男女。 12345ggplot(data = wdata) + geom_histogram(aes(x = weight)) + labs(title = '体重分布', x = '重量（公斤）', y = '数量') 结果如下图： 可以看到全部人群的重量分布有两个中心。如果这是一个正常的数据分析，我们会猜测可能有其他因素影响了分布，其中性别是最符合直觉的，所以这个时候我会对性别做一个分组，再画一张图。（虽然这里的数据是我直接 simulate 的，我已经提前知道答案了，但这个分析思路不会有改变）。 更新做图代码： 123456ggplot(data = wdata) + geom_histogram(aes(x = weight, fill = sex)) + labs(title = '体重分布', x = '重量（公斤）', y = '数量', fill = '性别') 这个时候我们可以清晰地看到不同性别有自己的体重分布。 density plotdensity plot 按照一个公式把数据转换成了“密度”，它跟 histogram 的区别可以查看这个回答。 代码如下： 123456ggplot(data = wdata) + geom_density(aes(x = weight, fill = sex)) + labs(title = '体重分布', x = '重量（公斤）', y = '数量', fill = '性别') 细心的你会发现，我们只修改了一行代码，具体来说，我们把 geom_histogram 变成了 geom_density，非常方便地生成了我们需要的图片。这就是 ggplot 厉害的地方。 结果如下图： 可以看到，两个组别的正态分布更加明显。 用 histogram 还是 density 呢？对比上面的两个图片，我们会看到：density 对趋势的展示更加明显。 我的思路如下： 在样本足够多的情况下，我会优先查看 density，然后查看 histogram 但如果样本量不足，用 density 可能会对数据做出过度处理，这个时候优先查看 histogram 如果数据需要跟外部团队沟通，优先展示 histogram，因为同事可能不太理解 density 的意思，而解释起来的沟通成本也非常高，这个时候，我永远选择最容易帮助沟通的方案。有些想展示自己专业性的分析师，可能会选择使用 density plot，这不是个对团队效率有帮助的习惯。 在两个方案能达到相同效果时，永远选择最利于沟通的方案，而不是最利于展示自己“实力”的方案。 上面这句话是我说的，也是我检验一个数据分析师是否合格的重要标准。当一个数据分析师优先展示自我而不是高效沟通时，他可能存在如下的问题： 缺乏沟通能力，甚至不是个 team player 缺乏成本意识，很难成为企业里足够好的 leader，毕竟，管理者最重要的工作之一是做投入产出分析 不真诚，\b甚至会有不诚实的嫌疑，这对数据工作是非常致命的 以上内容，也是我对自己的警醒。 引申：用 geom_area 实现类似 density 的效果ggplot 还有一个 geom_area 函数，能实现类似直方图的功能。 我们试试用 geom_area 修改代码，并尝试使用另一个主题。代码如下： 123456789ggplot(data = wdata) + geom_area(aes(x = weight, fill = sex), stat =\"bin\", alpha=0.6) + theme_classic() + theme(text=element_text(size=20, family=\"STFangsong\"), plot.title = element_text(hjust = 0.5)) + labs(title = '体重分布', x = '重量（公斤）', y = '数量', fill = '性别') 结果如图： 这是一个看起来很舒服的可视化数据了，相信也会让你的报告更有说服力。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据可视化","slug":"数据可视化","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"Closure: 以 Python 和 JavaScript 为例","slug":"2017-03-05-closure","date":"2017-03-04T16:17:33.000Z","updated":"2020-01-22T19:42:39.775Z","comments":true,"path":"2017/03/04/2017-03-05-closure/","link":"","permalink":"http://yoursite.com/2017/03/04/2017-03-05-closure/","excerpt":"\b\b计算机语言里有个常用的概念，叫 closure（闭包）。这里用 python 和 JavaScript 作为对照例子，解释一下 closure 的含义。 先看一个问题，下面一段 python 代码，会在 terminal 上打印什么呢？ 123456789a = 2def outer(): a = 1 def inner(): print(a) return innerfunc = outer()func()","text":"\b\b计算机语言里有个常用的概念，叫 closure（闭包）。这里用 python 和 JavaScript 作为对照例子，解释一下 closure 的含义。 先看一个问题，下面一段 python 代码，会在 terminal 上打印什么呢？ 123456789a = 2def outer(): a = 1 def inner(): print(a) return innerfunc = outer()func() 上面的代码出现了若干次 a，第1个 a 在“最外面”，第2个 a 在 outer 函数里，第3个 a 出现在 inner 函数里，而 inner 函数又在 outer 函数里。 上面这段话可以用 scope 的概念重新描述： 第1个 a 在 global scope 中，整段代码都可以使用 第2个 a 在 outer 函数的 scope 中 第3个 a 不是个变量，是对变量的使用，那么它会使用第1个a、还是第2个a、还是报错呢？ 答案：terminal 回打印出 1，也就是说，inner 函数使用了 outer 函数里的 a。 这里有两个值得深究的地方。我们一个个看。 1. 向上查询先看下面这段代码。 123456a = 1def func(): print(a)func() 在运行 func 函数时，计算机会现在 func 的 scope 寻找 a 变量，但我们没有定义 a 变量，\b这时计算机会“向上一层”查询，上一层就是 global scope，\b我们在上一层定义了 a 并令它为 1，计算机就认为自己找到了 a，于是打印出 a 的内容：1。 同样一段代码，可以在 JavaScript 中轻松实现： 1234567var a = 1function myFunc() { console.log(a);}myFunc() R 中也有类似的设计： 1234567a = 1my_function &lt;- function() { print(a)}my_function() 我们运行上面3段代码时，都会得到 1。 在最开始的代码段里，上一层的 a 在 outer 函数里，是1，此时计算机不再往上寻找 a，所以就打印出了 1。如果我们把 outer 函数里的 a = 1 删掉呢？此时代码如下： 12345678a = 2def outer(): def inner(): print(a) return innerfunc = outer()func() 因为找不到计算机在 outer 里找不到 a，它继续往上寻找，在 global scope 里找到了 a，于是打印出了 2。 这样的设计乍看之下不太友好：如果我们不小心在函数里使用了某个 global scope 的变量，计算机就不会报错，而是会继续运行程序。这岂不是不利于代码的稳定性。 虽然有这个潜在风险，很多语言还是选择了这个设计，自然是因为这个设计是有价值的。价值在哪儿呢？这就涉及到示例代码中第2个值得深究的地方了。 2. 函数可以返回函数在 python、R 和 JavaScript 里，函数都可以返回函数。 12345678def outer(): a = 1 def inner(): print(a) return innerfunc = outer()func() 我们的 outer 函数的 return 值是一个 inner 函数。通过 func = outer()，我们让 func 变成了 inner 函数。 这里值得注意的地方是，我们 return 的明明只是 inner 函数，代码里只有 print(a)这行，为什么这个 inner 函数会记住自己所在的 scope 里有个 a 变量呢？这就是 closure 这个概念了。 当我们在 outer 函数里返回 inner 函数时，与 inner 函数在同一个 scope 里面的变量也会被“包”进 inner 函数中，变成 inner 函数的 private variable。 这是一个非常有用的概念。 closure 的应用我最喜欢的 closure 应用场景，是批量生成函数。 问题场景：我需要生成一组幂函数的值，指数分别为 2、3、4, x 分别是 -10 到 10 之间的整数。 在我不知道 closure 时，我会想生成一个带有2个参数的函数，然后使用 list comprehension。 123456def power_func(x, power): return x ** power[ power_func(i, 2) for i in list(range(-10, 10))][ power_func(i, 3) for i in list(range(-10, 10))][ power_func(i, 4) for i in list(range(-10, 10))] 这是一个看上去简单的解答，但并不是一个代码层面更“好”的解答。因为，有可能我们想要在多种场合重复使用某几个幂指数的函数，比如幂指数为2的函数，可能在我们的计算里非常常用，这时最好的做法是生成一个幂指数为2的函数，然后重复使用它。 这时就需要使用 closure了。如果使用 closure，上面的问题会这样解答： 12345678910111213def power_func(power): def inner_func(x): return x ** power return inner_funcpower_two = power_func(2)power_three = power_func(3)power_four = power_func(4)[ power_two(i) for i in list(range(-10, 10))][ power_three(i) for i in list(range(-10, 10))][ power_four(i) for i in list(range(-10, 10))] 这段代码看上去更长，但从“思路”上其实方便，代码的可读性也强了非常多。 类似的思考方式其实是写代码到一定阶段后必然会碰到的：如何抽象地设计出一个生成函数的函数，让我们的代码可读性更高，更加 DRY（ don’t repeat yourself ）。 同样一段代码，如果使用 JavaScript，可以这样写： 1234567891011121314151617function powerFunc(power) { function innerFunc(x) { return Math.pow(x, power) } return innerFunc}var powerTwo = powerFunc(2)var powerThree = powerFunc(3)var powerFour = powerFunc(4)var numRange = Array.from(new Array(21), (x,i) =&gt; i - 10)console.log(numRange.map(el =&gt; powerTwo(el)))console.log(numRange.map(el =&gt; powerThree(el)))console.log(numRange.map(el =&gt; powerFour(el))) JavaScript 的连续箭头函数理解了 closure 的概念后，下面这段 JavaScript 代码就很好理解了： 1const makeAddFunc = adder =&gt; x =&gt; x + adder 这其实就是 closure 的箭头函数写法，这里连续使用了两个箭头函数。完整写法如下： 123456function makeAddFunc(adder) { function innerFunc(x) { return x + adder } return innerFunc} 我们可以用上面的 makeAddFunc 生成若干自己需要的函数： 12345addTwo = makeAddFunc(2)addThree = makeAddFunc(3)console.log(addTwo(5)) // print 7console.log(addThree(5)) // print 8 小结个人经验来说，closure 是一个“分水岭”，区分开新手 coder 和中级 coder。 如果我们对 closure 足够熟悉，我们会发现某些特定的场合简直是为 closure 天然而生。学会在这些场合使用 closure，会让我们的代码质量上一个台阶。 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"Coding","slug":"Coding","permalink":"http://yoursite.com/categories/Coding/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"},{"name":"JavaScript","slug":"JavaScript","permalink":"http://yoursite.com/tags/JavaScript/"}]},{"title":"ggplot系列之二：mosaic图","slug":"2017-02-03-ggplot-mosaic","date":"2017-02-03T04:46:47.000Z","updated":"2020-01-22T19:42:39.775Z","comments":true,"path":"2017/02/03/2017-02-03-ggplot-mosaic/","link":"","permalink":"http://yoursite.com/2017/02/03/2017-02-03-ggplot-mosaic/","excerpt":"上一篇文章介绍了 ggplot 的散点图。散点图太常见了，这篇文章介绍下不那么常见，但用起来很酷的 mosaic 图。 mosaic 图在如下场景使用：展示两组 categorical data 的情况。","text":"上一篇文章介绍了 ggplot 的散点图。散点图太常见了，这篇文章介绍下不那么常见，但用起来很酷的 mosaic 图。 mosaic 图在如下场景使用：展示两组 categorical data 的情况。 使用 ggmosaic 包 君子性非异也，善假于物也。 ggplot2 可以用柱状图（geom_bar）的方法生成 mosaic 图，需要对参数做一些调整。 但聪明的开发者们早已经基于 ggplot 封装了一个包：ggmosaic。我们可以像调用 geom_bar 一样调用 geom_mosaic。 我们先安装 ggmosaic 包： 1install.packages('ggmosaic') 这里使用的是 ggmosaic 包里的 fly 数据集。 Fly 数据集调查了乘飞机的礼貌问题，比如： 你认为在飞机上把座位往后倾斜礼貌吗 你会倾斜座椅吗 你觉得带小宝宝坐飞机礼貌吗 数据共有 1040 行，共27个变量。 问题1：态度和行为的关系我想了解的问题是：觉得倾斜座椅很粗鲁都人，自己会倾斜座椅吗？换句话说，大家言行合一吗？ 我的猜测是：觉得倾斜椅子粗鲁的人，自己应该也不怎么会倾斜椅子。 代码如下： 123456ggplot(data = fly) + geom_mosaic(aes(x = product(RudeToRecline), fill=DoYouRecline)) + labs(title = '倾斜座椅的态度 vs 行为', x = '你觉得倾斜座椅粗鲁吗', y = '你倾斜座椅吗', fill = '你倾斜座椅吗') 图片如下（为了 x 轴坐标的展示，图片拉长了）： 可以从图中看到，认为座椅倾斜很粗鲁的人，确实也更不会倾斜座椅。符合猜测。 问题2：有小孩的人是否更能容忍小孩呢数据集中有这么两个变量： 你是否有18岁以下的小孩 你觉得带小宝宝坐飞机粗鲁吗 这让我产生了一个猜想：有小孩的人会更能容忍别人带小宝宝。 为了验证这个假设，我们对上面两个变量做个 mosaic 图。 代码如下： 123456ggplot(data = fly) + geom_mosaic(aes(x = product(Child18), fill=RudeToBringBaby)) + labs(title = '“有小孩\"和\"觉得带小宝宝乘飞机粗鲁吗\"的关系', x = '你有18岁以下的小孩吗', y = '带小宝宝乘飞机粗鲁吗', fill = '带小宝宝乘飞机粗鲁吗') 图片结果如下： 可以从图片中看出，有18岁小孩的人，更倾向于认为带宝宝坐飞机是不粗鲁的。 问题3：年纪越大是否越能忍受小孩呢？我想到一个新问题，是否年纪越大的人越能忍受小孩呢？ 这个问题需要两个变量： 年龄，在这里也是 categorical data （严格得说是 ordinal data，这里的变量都是，但这里不做区分） 你觉得带小宝宝坐飞机粗鲁吗 123456ggplot(data = fly) + geom_mosaic(aes(x = product(Age), fill=RudeToBringBaby)) + labs(title = '\"年龄\"和“觉得带小宝宝乘飞机粗鲁吗”的关系', x = '你的年龄', y = '带小宝宝乘飞机粗鲁吗', fill = '带小宝宝乘飞机粗鲁吗') 图片结果如下： 可以看出：30岁以下的人会相对不能接受带宝宝乘飞机的行为。 小结 Mosaic 图适合用在两个 categorical variable 的展示上 ggmosaic 是个基于 ggplot 的 package，能方便地制作 mosaic 图 document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据可视化","slug":"数据可视化","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]},{"title":"ggplot系列之一：散点图","slug":"2017-01-05-ggplot散点图","date":"2017-01-05T13:52:50.000Z","updated":"2020-01-22T19:42:39.775Z","comments":true,"path":"2017/01/05/2017-01-05-ggplot散点图/","link":"","permalink":"http://yoursite.com/2017/01/05/2017-01-05-ggplot%E6%95%A3%E7%82%B9%E5%9B%BE/","excerpt":"ggplot2 是 R 语言大神 Hadly Wickham 开发的数据可视化工具。Wickham 为数据可视化抽象出了一套“语法”，掌握这套语法后就可以系统性地生成可视化数据。 \b这个系列文章会介绍如何使用 ggplot2 做图。 本篇介绍最常见的散点图。","text":"ggplot2 是 R 语言大神 Hadly Wickham 开发的数据可视化工具。Wickham 为数据可视化抽象出了一套“语法”，掌握这套语法后就可以系统性地生成可视化数据。 \b这个系列文章会介绍如何使用 ggplot2 做图。 本篇介绍最常见的散点图。 准备数据每次我拿到数据的第一件事情，就是看看不同变量的散点图长啥样，看到散点图之后，就能对变量之间的关系做一定猜测了。 我们先准备一份用来画图的数据。 12345set.seed(955)obs_num &lt;- 40dat &lt;- data.frame(cond = rep(c(\"A\", \"B\"), each = obs_num / 2), x = 1:obs_num + rnorm(obs_num, sd = 3), y = 1:obs_num + rnorm(obs_num, sd = 3)) 我们的模拟数据有3个变量，x 和 y 是数字，cond 是一个 categorical 变量。 最简单的散点图下面画一个最简单的散点图。 123ggplot(dat, aes(x = x, y = y)) + geom_point() + labs(title = '这是一个最简单的散点图') 结果如下图： 添加拟合曲线有时我们想更清晰地看到数据趋势，ggplot 可以帮我们快速添加一条拟合曲线。 1234ggplot(dat, aes(x = x, y = y)) + geom_point() + geom_smooth() + labs(title = '带拟合曲线的散点图') 结果如下图： 给不同组的点上色如果数据中有不同的分组，我们会想在散点图中看到不同组的情况。 1234ggplot(dat, aes(x = x, y = y, color = cond)) + geom_point() + labs(title = '需要用颜色分组的散点图', color = '分组') 结果如下图： 使用 facets如果组别太多，上色可能会让人眼花缭乱，这时我们可以使用 facets。 1234ggplot(dat, aes(x = x, y = y)) + geom_point() + facet_wrap(~ cond) + labs(title = '使用 facets 的散点图') 结果如下图： 当然，我们也可以把颜色和 cond 结合起来，生成本文最开始那张图片。代码如下： 123ggplot(dat, aes(x = x, y = y, color = cond)) + geom_point() + facet_wrap(~ cond) document.querySelectorAll('.github-emoji') .forEach(el => { if (!el.dataset.src) { return; } const img = document.createElement('img'); img.style = 'display:none !important;'; img.src = el.dataset.src; img.addEventListener('error', () => { img.remove(); el.style.color = 'inherit'; el.style.backgroundImage = 'none'; el.style.background = 'none'; }); img.addEventListener('load', () => { img.remove(); }); document.body.appendChild(img); });","categories":[{"name":"数据可视化","slug":"数据可视化","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"}],"tags":[{"name":"R","slug":"R","permalink":"http://yoursite.com/tags/R/"}]}]}